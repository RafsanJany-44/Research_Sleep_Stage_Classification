{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RafsanJany-44/Research_Sleep_Stage_Classification/blob/main/ANN_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "KPnkjM0D7riO"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading Dataset\n",
        "data = pd.read_csv(\"https://raw.githubusercontent.com/RafsanJany-44/Thesis_Project/main/All_DATA/without_sn_and_Epoch/EEG_HMC.csv\")"
      ],
      "metadata": {
        "id": "dBa0SHNFndqo"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.iloc[:, 1:].values\n",
        "Y = data.iloc[:, 0].values"
      ],
      "metadata": {
        "id": "6q5hpx-3nHIs"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Encoding Categorical the sleep_stage\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "LE1 = LabelEncoder()\n",
        "Y = np.array(LE1.fit_transform(Y))"
      ],
      "metadata": {
        "id": "-IUhl3tRnMCu"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Encoding Categorical variable Geography\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "ct =ColumnTransformer(transformers=[('encoder',OneHotEncoder(),[1])],remainder=\"passthrough\")\n",
        "X = np.array(ct.fit_transform(X))"
      ],
      "metadata": {
        "id": "exC-gMyanMfH"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting dataset into training and testing dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,Y,test_size=0.2,random_state=0)"
      ],
      "metadata": {
        "id": "X3Gotf3InPYz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Performing Feature Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ],
      "metadata": {
        "id": "G-Mxsm15h9qE"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCYh6eOu7rif",
        "outputId": "edd8ebc1-db57-46ad-8dac-07f92b001d5b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "86760"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "len(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwal07Pi7rik",
        "outputId": "63c40edb-f711-48b8-a7a4-09b8b6e5571d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21691"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "len(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mdsvw9Bc7rim",
        "outputId": "1e1d7754-43fe-4ad1-fbd4-d42293121b87"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(86760, 215)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "X_train.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(500, input_shape=(215,), activation='relu'), # input layer\n",
        "    keras.layers.Dense(350, activation='sigmoid'),\n",
        "    keras.layers.Dense(250, activation='sigmoid'),\n",
        "    keras.layers.Dense(150, activation='sigmoid'),\n",
        "    keras.layers.Dense(75, activation='softmax')                    # output layer\n",
        "])\n",
        "\n",
        "'''model = keras.Sequential([\n",
        "    keras.layers.Dense(100, input_shape=(215,), activation='relu'), # input layer\n",
        "    #keras.layers.Dense(350, activation='sigmoid'),\n",
        "    #keras.layers.Dense(250, activation='sigmoid'),\n",
        "    keras.layers.Dense(75, activation='sigmoid'),\n",
        "    keras.layers.Dense(25, activation='softmax')                    # output layer\n",
        "])'''\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, y_train, epochs=560)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7m1Ujz34ZvPh",
        "outputId": "52e931d5-388d-44d3-aca6-c7f0aee1cd9d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.9218 - accuracy: 0.6350\n",
            "Epoch 2/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.7663 - accuracy: 0.6971\n",
            "Epoch 3/560\n",
            "2712/2712 [==============================] - 22s 8ms/step - loss: 0.7125 - accuracy: 0.7185\n",
            "Epoch 4/560\n",
            "2712/2712 [==============================] - 18s 7ms/step - loss: 0.6728 - accuracy: 0.7349\n",
            "Epoch 5/560\n",
            "2712/2712 [==============================] - 20s 7ms/step - loss: 0.6418 - accuracy: 0.7451\n",
            "Epoch 6/560\n",
            "2712/2712 [==============================] - 20s 7ms/step - loss: 0.6146 - accuracy: 0.7576\n",
            "Epoch 7/560\n",
            "2712/2712 [==============================] - 20s 7ms/step - loss: 0.5911 - accuracy: 0.7665\n",
            "Epoch 8/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.5703 - accuracy: 0.7747\n",
            "Epoch 9/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.5480 - accuracy: 0.7825\n",
            "Epoch 10/560\n",
            "2712/2712 [==============================] - 20s 7ms/step - loss: 0.5296 - accuracy: 0.7914\n",
            "Epoch 11/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.5105 - accuracy: 0.7975\n",
            "Epoch 12/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.4909 - accuracy: 0.8047\n",
            "Epoch 13/560\n",
            "2712/2712 [==============================] - 18s 7ms/step - loss: 0.4722 - accuracy: 0.8126\n",
            "Epoch 14/560\n",
            "2712/2712 [==============================] - 18s 7ms/step - loss: 0.4535 - accuracy: 0.8193\n",
            "Epoch 15/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.4342 - accuracy: 0.8262\n",
            "Epoch 16/560\n",
            "2712/2712 [==============================] - 18s 7ms/step - loss: 0.4170 - accuracy: 0.8345\n",
            "Epoch 17/560\n",
            "2712/2712 [==============================] - 18s 6ms/step - loss: 0.3992 - accuracy: 0.8417\n",
            "Epoch 18/560\n",
            "2712/2712 [==============================] - 20s 7ms/step - loss: 0.3825 - accuracy: 0.8480\n",
            "Epoch 19/560\n",
            "2712/2712 [==============================] - 25s 9ms/step - loss: 0.3647 - accuracy: 0.8548\n",
            "Epoch 20/560\n",
            "2712/2712 [==============================] - 28s 10ms/step - loss: 0.3481 - accuracy: 0.8618\n",
            "Epoch 21/560\n",
            "2712/2712 [==============================] - 21s 8ms/step - loss: 0.3310 - accuracy: 0.8699\n",
            "Epoch 22/560\n",
            "2712/2712 [==============================] - 18s 7ms/step - loss: 0.3170 - accuracy: 0.8736\n",
            "Epoch 23/560\n",
            "2712/2712 [==============================] - 18s 7ms/step - loss: 0.3011 - accuracy: 0.8811\n",
            "Epoch 24/560\n",
            "2712/2712 [==============================] - 18s 7ms/step - loss: 0.2849 - accuracy: 0.8867\n",
            "Epoch 25/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.2736 - accuracy: 0.8916\n",
            "Epoch 26/560\n",
            "2712/2712 [==============================] - 22s 8ms/step - loss: 0.2608 - accuracy: 0.8966\n",
            "Epoch 27/560\n",
            "2712/2712 [==============================] - 20s 7ms/step - loss: 0.2493 - accuracy: 0.9011\n",
            "Epoch 28/560\n",
            "2712/2712 [==============================] - 18s 7ms/step - loss: 0.2404 - accuracy: 0.9065\n",
            "Epoch 29/560\n",
            "2712/2712 [==============================] - 18s 7ms/step - loss: 0.2296 - accuracy: 0.9095\n",
            "Epoch 30/560\n",
            "2712/2712 [==============================] - 18s 7ms/step - loss: 0.2204 - accuracy: 0.9130\n",
            "Epoch 31/560\n",
            "2712/2712 [==============================] - 21s 8ms/step - loss: 0.2132 - accuracy: 0.9165\n",
            "Epoch 32/560\n",
            "2712/2712 [==============================] - 21s 8ms/step - loss: 0.2023 - accuracy: 0.9221\n",
            "Epoch 33/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.1964 - accuracy: 0.9233\n",
            "Epoch 34/560\n",
            "2712/2712 [==============================] - 18s 7ms/step - loss: 0.1893 - accuracy: 0.9268\n",
            "Epoch 35/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.1859 - accuracy: 0.9278\n",
            "Epoch 36/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.1783 - accuracy: 0.9312\n",
            "Epoch 37/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.1753 - accuracy: 0.9321\n",
            "Epoch 38/560\n",
            "2712/2712 [==============================] - 18s 7ms/step - loss: 0.1698 - accuracy: 0.9345\n",
            "Epoch 39/560\n",
            "2712/2712 [==============================] - 18s 7ms/step - loss: 0.1646 - accuracy: 0.9370\n",
            "Epoch 40/560\n",
            "2712/2712 [==============================] - 20s 7ms/step - loss: 0.1628 - accuracy: 0.9374\n",
            "Epoch 41/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.1606 - accuracy: 0.9380\n",
            "Epoch 42/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.1551 - accuracy: 0.9412\n",
            "Epoch 43/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.1527 - accuracy: 0.9414\n",
            "Epoch 44/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.1504 - accuracy: 0.9432\n",
            "Epoch 45/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.1496 - accuracy: 0.9430\n",
            "Epoch 46/560\n",
            "2712/2712 [==============================] - 20s 7ms/step - loss: 0.1447 - accuracy: 0.9446\n",
            "Epoch 47/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.1451 - accuracy: 0.9444\n",
            "Epoch 48/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.1417 - accuracy: 0.9459\n",
            "Epoch 49/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.1437 - accuracy: 0.9453\n",
            "Epoch 50/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.1377 - accuracy: 0.9479\n",
            "Epoch 51/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.1370 - accuracy: 0.9489\n",
            "Epoch 52/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.1372 - accuracy: 0.9478\n",
            "Epoch 53/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.1328 - accuracy: 0.9499\n",
            "Epoch 54/560\n",
            "2712/2712 [==============================] - 20s 7ms/step - loss: 0.1321 - accuracy: 0.9500\n",
            "Epoch 55/560\n",
            "2712/2712 [==============================] - 18s 7ms/step - loss: 0.1317 - accuracy: 0.9504\n",
            "Epoch 56/560\n",
            "2712/2712 [==============================] - 17s 6ms/step - loss: 0.1327 - accuracy: 0.9493\n",
            "Epoch 57/560\n",
            "2712/2712 [==============================] - 18s 7ms/step - loss: 0.1279 - accuracy: 0.9515\n",
            "Epoch 58/560\n",
            "2712/2712 [==============================] - 18s 7ms/step - loss: 0.1296 - accuracy: 0.9509\n",
            "Epoch 59/560\n",
            "2712/2712 [==============================] - 18s 7ms/step - loss: 0.1246 - accuracy: 0.9529\n",
            "Epoch 60/560\n",
            "2712/2712 [==============================] - 18s 6ms/step - loss: 0.1247 - accuracy: 0.9526\n",
            "Epoch 61/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.1246 - accuracy: 0.9529\n",
            "Epoch 62/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.1235 - accuracy: 0.9531\n",
            "Epoch 63/560\n",
            "2712/2712 [==============================] - 22s 8ms/step - loss: 0.1249 - accuracy: 0.9526\n",
            "Epoch 64/560\n",
            "2712/2712 [==============================] - 18s 7ms/step - loss: 0.1224 - accuracy: 0.9530\n",
            "Epoch 65/560\n",
            "2712/2712 [==============================] - 18s 7ms/step - loss: 0.1218 - accuracy: 0.9536\n",
            "Epoch 66/560\n",
            "2712/2712 [==============================] - 18s 7ms/step - loss: 0.1214 - accuracy: 0.9541\n",
            "Epoch 67/560\n",
            "2712/2712 [==============================] - 18s 7ms/step - loss: 0.1198 - accuracy: 0.9545\n",
            "Epoch 68/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.1195 - accuracy: 0.9543\n",
            "Epoch 69/560\n",
            "2712/2712 [==============================] - 21s 8ms/step - loss: 0.1191 - accuracy: 0.9548\n",
            "Epoch 70/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.1194 - accuracy: 0.9549\n",
            "Epoch 71/560\n",
            "2712/2712 [==============================] - 22s 8ms/step - loss: 0.1163 - accuracy: 0.9560\n",
            "Epoch 72/560\n",
            "2712/2712 [==============================] - 23s 8ms/step - loss: 0.1153 - accuracy: 0.9553\n",
            "Epoch 73/560\n",
            "2712/2712 [==============================] - 23s 8ms/step - loss: 0.1184 - accuracy: 0.9558\n",
            "Epoch 74/560\n",
            "2712/2712 [==============================] - 23s 9ms/step - loss: 0.1157 - accuracy: 0.9558\n",
            "Epoch 75/560\n",
            "2712/2712 [==============================] - 27s 10ms/step - loss: 0.1143 - accuracy: 0.9564\n",
            "Epoch 76/560\n",
            "2712/2712 [==============================] - 23s 9ms/step - loss: 0.1144 - accuracy: 0.9568\n",
            "Epoch 77/560\n",
            "2712/2712 [==============================] - 26s 9ms/step - loss: 0.1129 - accuracy: 0.9572\n",
            "Epoch 78/560\n",
            "2712/2712 [==============================] - 25s 9ms/step - loss: 0.1125 - accuracy: 0.9577\n",
            "Epoch 79/560\n",
            "2712/2712 [==============================] - 26s 9ms/step - loss: 0.1142 - accuracy: 0.9568\n",
            "Epoch 80/560\n",
            "2712/2712 [==============================] - 28s 10ms/step - loss: 0.1131 - accuracy: 0.9578\n",
            "Epoch 81/560\n",
            "2712/2712 [==============================] - 28s 10ms/step - loss: 0.1109 - accuracy: 0.9582\n",
            "Epoch 82/560\n",
            "2712/2712 [==============================] - 27s 10ms/step - loss: 0.1120 - accuracy: 0.9573\n",
            "Epoch 83/560\n",
            "2712/2712 [==============================] - 25s 9ms/step - loss: 0.1112 - accuracy: 0.9576\n",
            "Epoch 84/560\n",
            "2712/2712 [==============================] - 26s 10ms/step - loss: 0.1118 - accuracy: 0.9577\n",
            "Epoch 85/560\n",
            "2712/2712 [==============================] - 22s 8ms/step - loss: 0.1102 - accuracy: 0.9581\n",
            "Epoch 86/560\n",
            "2712/2712 [==============================] - 23s 8ms/step - loss: 0.1081 - accuracy: 0.9596\n",
            "Epoch 87/560\n",
            "2712/2712 [==============================] - 24s 9ms/step - loss: 0.1121 - accuracy: 0.9580\n",
            "Epoch 88/560\n",
            "2712/2712 [==============================] - 26s 10ms/step - loss: 0.1069 - accuracy: 0.9593\n",
            "Epoch 89/560\n",
            "2712/2712 [==============================] - 34s 13ms/step - loss: 0.1079 - accuracy: 0.9592\n",
            "Epoch 90/560\n",
            "2712/2712 [==============================] - 34s 12ms/step - loss: 0.1076 - accuracy: 0.9594\n",
            "Epoch 91/560\n",
            "2712/2712 [==============================] - 28s 10ms/step - loss: 0.1078 - accuracy: 0.9595\n",
            "Epoch 92/560\n",
            "2712/2712 [==============================] - 30s 11ms/step - loss: 0.1070 - accuracy: 0.9594\n",
            "Epoch 93/560\n",
            "2712/2712 [==============================] - 29s 11ms/step - loss: 0.1091 - accuracy: 0.9587\n",
            "Epoch 94/560\n",
            "2712/2712 [==============================] - 26s 10ms/step - loss: 0.1068 - accuracy: 0.9601\n",
            "Epoch 95/560\n",
            "2712/2712 [==============================] - 26s 9ms/step - loss: 0.1070 - accuracy: 0.9601\n",
            "Epoch 96/560\n",
            "2712/2712 [==============================] - 22s 8ms/step - loss: 0.1066 - accuracy: 0.9596\n",
            "Epoch 97/560\n",
            "2712/2712 [==============================] - 22s 8ms/step - loss: 0.1061 - accuracy: 0.9600\n",
            "Epoch 98/560\n",
            "2712/2712 [==============================] - 24s 9ms/step - loss: 0.1056 - accuracy: 0.9606\n",
            "Epoch 99/560\n",
            "2712/2712 [==============================] - 24s 9ms/step - loss: 0.1030 - accuracy: 0.9607\n",
            "Epoch 100/560\n",
            "2712/2712 [==============================] - 24s 9ms/step - loss: 0.1045 - accuracy: 0.9604\n",
            "Epoch 101/560\n",
            "2712/2712 [==============================] - 22s 8ms/step - loss: 0.1015 - accuracy: 0.9621\n",
            "Epoch 102/560\n",
            "2712/2712 [==============================] - 28s 10ms/step - loss: 0.1063 - accuracy: 0.9597\n",
            "Epoch 103/560\n",
            "2712/2712 [==============================] - 29s 11ms/step - loss: 0.1031 - accuracy: 0.9613\n",
            "Epoch 104/560\n",
            "2712/2712 [==============================] - 30s 11ms/step - loss: 0.1051 - accuracy: 0.9606\n",
            "Epoch 105/560\n",
            "2712/2712 [==============================] - 27s 10ms/step - loss: 0.1022 - accuracy: 0.9618\n",
            "Epoch 106/560\n",
            "2712/2712 [==============================] - 31s 12ms/step - loss: 0.1044 - accuracy: 0.9613\n",
            "Epoch 107/560\n",
            "2712/2712 [==============================] - 25s 9ms/step - loss: 0.1032 - accuracy: 0.9614\n",
            "Epoch 108/560\n",
            "2712/2712 [==============================] - 24s 9ms/step - loss: 0.1040 - accuracy: 0.9612\n",
            "Epoch 109/560\n",
            "2712/2712 [==============================] - 23s 9ms/step - loss: 0.1029 - accuracy: 0.9609\n",
            "Epoch 110/560\n",
            "2712/2712 [==============================] - 24s 9ms/step - loss: 0.1007 - accuracy: 0.9621\n",
            "Epoch 111/560\n",
            "2712/2712 [==============================] - 23s 9ms/step - loss: 0.1010 - accuracy: 0.9617\n",
            "Epoch 112/560\n",
            "2712/2712 [==============================] - 25s 9ms/step - loss: 0.1025 - accuracy: 0.9609\n",
            "Epoch 113/560\n",
            "2712/2712 [==============================] - 25s 9ms/step - loss: 0.0999 - accuracy: 0.9619\n",
            "Epoch 114/560\n",
            "2712/2712 [==============================] - 23s 8ms/step - loss: 0.1011 - accuracy: 0.9621\n",
            "Epoch 115/560\n",
            "2712/2712 [==============================] - 24s 9ms/step - loss: 0.1005 - accuracy: 0.9614\n",
            "Epoch 116/560\n",
            "2712/2712 [==============================] - 21s 8ms/step - loss: 0.0999 - accuracy: 0.9622\n",
            "Epoch 117/560\n",
            "2712/2712 [==============================] - 22s 8ms/step - loss: 0.1041 - accuracy: 0.9609\n",
            "Epoch 118/560\n",
            "2712/2712 [==============================] - 21s 8ms/step - loss: 0.1011 - accuracy: 0.9622\n",
            "Epoch 119/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0990 - accuracy: 0.9623\n",
            "Epoch 120/560\n",
            "2712/2712 [==============================] - 20s 8ms/step - loss: 0.1017 - accuracy: 0.9615\n",
            "Epoch 121/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.1008 - accuracy: 0.9620\n",
            "Epoch 122/560\n",
            "2712/2712 [==============================] - 18s 7ms/step - loss: 0.0997 - accuracy: 0.9623\n",
            "Epoch 123/560\n",
            "2712/2712 [==============================] - 21s 8ms/step - loss: 0.0986 - accuracy: 0.9631\n",
            "Epoch 124/560\n",
            "2712/2712 [==============================] - 23s 8ms/step - loss: 0.1010 - accuracy: 0.9611\n",
            "Epoch 125/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.1004 - accuracy: 0.9620\n",
            "Epoch 126/560\n",
            "2712/2712 [==============================] - 21s 8ms/step - loss: 0.0995 - accuracy: 0.9620\n",
            "Epoch 127/560\n",
            "2712/2712 [==============================] - 24s 9ms/step - loss: 0.1012 - accuracy: 0.9622\n",
            "Epoch 128/560\n",
            "2712/2712 [==============================] - 24s 9ms/step - loss: 0.0990 - accuracy: 0.9628\n",
            "Epoch 129/560\n",
            "2712/2712 [==============================] - 21s 8ms/step - loss: 0.1025 - accuracy: 0.9611\n",
            "Epoch 130/560\n",
            "2712/2712 [==============================] - 21s 8ms/step - loss: 0.0978 - accuracy: 0.9631\n",
            "Epoch 131/560\n",
            "2712/2712 [==============================] - 21s 8ms/step - loss: 0.1010 - accuracy: 0.9617\n",
            "Epoch 132/560\n",
            "2712/2712 [==============================] - 25s 9ms/step - loss: 0.0977 - accuracy: 0.9627\n",
            "Epoch 133/560\n",
            "2712/2712 [==============================] - 22s 8ms/step - loss: 0.0967 - accuracy: 0.9634\n",
            "Epoch 134/560\n",
            "2712/2712 [==============================] - 22s 8ms/step - loss: 0.0997 - accuracy: 0.9626\n",
            "Epoch 135/560\n",
            "2712/2712 [==============================] - 20s 7ms/step - loss: 0.0977 - accuracy: 0.9628\n",
            "Epoch 136/560\n",
            "2712/2712 [==============================] - 21s 8ms/step - loss: 0.0969 - accuracy: 0.9639\n",
            "Epoch 137/560\n",
            "2712/2712 [==============================] - 21s 8ms/step - loss: 0.0979 - accuracy: 0.9631\n",
            "Epoch 138/560\n",
            "2712/2712 [==============================] - 22s 8ms/step - loss: 0.0971 - accuracy: 0.9630\n",
            "Epoch 139/560\n",
            "2712/2712 [==============================] - 25s 9ms/step - loss: 0.1004 - accuracy: 0.9622\n",
            "Epoch 140/560\n",
            "2712/2712 [==============================] - 22s 8ms/step - loss: 0.0959 - accuracy: 0.9636\n",
            "Epoch 141/560\n",
            "2712/2712 [==============================] - 23s 8ms/step - loss: 0.0976 - accuracy: 0.9633\n",
            "Epoch 142/560\n",
            "2712/2712 [==============================] - 20s 7ms/step - loss: 0.0965 - accuracy: 0.9637\n",
            "Epoch 143/560\n",
            "2712/2712 [==============================] - 20s 7ms/step - loss: 0.0957 - accuracy: 0.9638\n",
            "Epoch 144/560\n",
            "2712/2712 [==============================] - 23s 9ms/step - loss: 0.0952 - accuracy: 0.9638\n",
            "Epoch 145/560\n",
            "2712/2712 [==============================] - 20s 7ms/step - loss: 0.0942 - accuracy: 0.9644\n",
            "Epoch 146/560\n",
            "2712/2712 [==============================] - 20s 7ms/step - loss: 0.0968 - accuracy: 0.9634\n",
            "Epoch 147/560\n",
            "2712/2712 [==============================] - 23s 8ms/step - loss: 0.0952 - accuracy: 0.9634\n",
            "Epoch 148/560\n",
            "2712/2712 [==============================] - 20s 8ms/step - loss: 0.0955 - accuracy: 0.9638\n",
            "Epoch 149/560\n",
            "2712/2712 [==============================] - 21s 8ms/step - loss: 0.0957 - accuracy: 0.9637\n",
            "Epoch 150/560\n",
            "2712/2712 [==============================] - 22s 8ms/step - loss: 0.0967 - accuracy: 0.9639\n",
            "Epoch 151/560\n",
            "2712/2712 [==============================] - 20s 7ms/step - loss: 0.0958 - accuracy: 0.9633\n",
            "Epoch 152/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0952 - accuracy: 0.9640\n",
            "Epoch 153/560\n",
            "2712/2712 [==============================] - 23s 8ms/step - loss: 0.0984 - accuracy: 0.9630\n",
            "Epoch 154/560\n",
            "2712/2712 [==============================] - 23s 9ms/step - loss: 0.0969 - accuracy: 0.9637\n",
            "Epoch 155/560\n",
            "2712/2712 [==============================] - 23s 8ms/step - loss: 0.0945 - accuracy: 0.9638\n",
            "Epoch 156/560\n",
            "2712/2712 [==============================] - 24s 9ms/step - loss: 0.0932 - accuracy: 0.9645\n",
            "Epoch 157/560\n",
            "2712/2712 [==============================] - 23s 9ms/step - loss: 0.0953 - accuracy: 0.9641\n",
            "Epoch 158/560\n",
            "2712/2712 [==============================] - 21s 8ms/step - loss: 0.0951 - accuracy: 0.9637\n",
            "Epoch 159/560\n",
            "2712/2712 [==============================] - 21s 8ms/step - loss: 0.0936 - accuracy: 0.9646\n",
            "Epoch 160/560\n",
            "2712/2712 [==============================] - 22s 8ms/step - loss: 0.0948 - accuracy: 0.9644\n",
            "Epoch 161/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0982 - accuracy: 0.9627\n",
            "Epoch 162/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0941 - accuracy: 0.9642\n",
            "Epoch 163/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0959 - accuracy: 0.9642\n",
            "Epoch 164/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0943 - accuracy: 0.9644\n",
            "Epoch 165/560\n",
            "2712/2712 [==============================] - 20s 7ms/step - loss: 0.0944 - accuracy: 0.9641\n",
            "Epoch 166/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0953 - accuracy: 0.9638\n",
            "Epoch 167/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0973 - accuracy: 0.9631\n",
            "Epoch 168/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0951 - accuracy: 0.9639\n",
            "Epoch 169/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0941 - accuracy: 0.9645\n",
            "Epoch 170/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0928 - accuracy: 0.9649\n",
            "Epoch 171/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0926 - accuracy: 0.9650\n",
            "Epoch 172/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0921 - accuracy: 0.9647\n",
            "Epoch 173/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0954 - accuracy: 0.9641\n",
            "Epoch 174/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0940 - accuracy: 0.9645\n",
            "Epoch 175/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0910 - accuracy: 0.9655\n",
            "Epoch 176/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0951 - accuracy: 0.9637\n",
            "Epoch 177/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0934 - accuracy: 0.9644\n",
            "Epoch 178/560\n",
            "2712/2712 [==============================] - 20s 7ms/step - loss: 0.0922 - accuracy: 0.9645\n",
            "Epoch 179/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0932 - accuracy: 0.9650\n",
            "Epoch 180/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0915 - accuracy: 0.9650\n",
            "Epoch 181/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0904 - accuracy: 0.9657\n",
            "Epoch 182/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0928 - accuracy: 0.9649\n",
            "Epoch 183/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0933 - accuracy: 0.9645\n",
            "Epoch 184/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0925 - accuracy: 0.9655\n",
            "Epoch 185/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0908 - accuracy: 0.9660\n",
            "Epoch 186/560\n",
            "2712/2712 [==============================] - 20s 7ms/step - loss: 0.0922 - accuracy: 0.9652\n",
            "Epoch 187/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0921 - accuracy: 0.9647\n",
            "Epoch 188/560\n",
            "2712/2712 [==============================] - 20s 7ms/step - loss: 0.0928 - accuracy: 0.9654\n",
            "Epoch 189/560\n",
            "2712/2712 [==============================] - 21s 8ms/step - loss: 0.0947 - accuracy: 0.9644\n",
            "Epoch 190/560\n",
            "2712/2712 [==============================] - 22s 8ms/step - loss: 0.0922 - accuracy: 0.9651\n",
            "Epoch 191/560\n",
            "2712/2712 [==============================] - 21s 8ms/step - loss: 0.0944 - accuracy: 0.9649\n",
            "Epoch 192/560\n",
            "2712/2712 [==============================] - 21s 8ms/step - loss: 0.0931 - accuracy: 0.9650\n",
            "Epoch 193/560\n",
            "2712/2712 [==============================] - 21s 8ms/step - loss: 0.0909 - accuracy: 0.9654\n",
            "Epoch 194/560\n",
            "2712/2712 [==============================] - 21s 8ms/step - loss: 0.0899 - accuracy: 0.9659\n",
            "Epoch 195/560\n",
            "2712/2712 [==============================] - 21s 8ms/step - loss: 0.0928 - accuracy: 0.9653\n",
            "Epoch 196/560\n",
            "2712/2712 [==============================] - 21s 8ms/step - loss: 0.0916 - accuracy: 0.9654\n",
            "Epoch 197/560\n",
            "2712/2712 [==============================] - 22s 8ms/step - loss: 0.0915 - accuracy: 0.9656\n",
            "Epoch 198/560\n",
            "2712/2712 [==============================] - 23s 9ms/step - loss: 0.0922 - accuracy: 0.9651\n",
            "Epoch 199/560\n",
            "2712/2712 [==============================] - 22s 8ms/step - loss: 0.0915 - accuracy: 0.9659\n",
            "Epoch 200/560\n",
            "2712/2712 [==============================] - 21s 8ms/step - loss: 0.0923 - accuracy: 0.9653\n",
            "Epoch 201/560\n",
            "2712/2712 [==============================] - 22s 8ms/step - loss: 0.0904 - accuracy: 0.9655\n",
            "Epoch 202/560\n",
            "2712/2712 [==============================] - 20s 7ms/step - loss: 0.0927 - accuracy: 0.9647\n",
            "Epoch 203/560\n",
            "2712/2712 [==============================] - 22s 8ms/step - loss: 0.0922 - accuracy: 0.9657\n",
            "Epoch 204/560\n",
            "2712/2712 [==============================] - 22s 8ms/step - loss: 0.0967 - accuracy: 0.9634\n",
            "Epoch 205/560\n",
            "2712/2712 [==============================] - 22s 8ms/step - loss: 0.0911 - accuracy: 0.9653\n",
            "Epoch 206/560\n",
            "2712/2712 [==============================] - 22s 8ms/step - loss: 0.0933 - accuracy: 0.9647\n",
            "Epoch 207/560\n",
            "2712/2712 [==============================] - 22s 8ms/step - loss: 0.0930 - accuracy: 0.9648\n",
            "Epoch 208/560\n",
            "2712/2712 [==============================] - 24s 9ms/step - loss: 0.0950 - accuracy: 0.9646\n",
            "Epoch 209/560\n",
            "2712/2712 [==============================] - 24s 9ms/step - loss: 0.0924 - accuracy: 0.9653\n",
            "Epoch 210/560\n",
            "2712/2712 [==============================] - 23s 8ms/step - loss: 0.0895 - accuracy: 0.9660\n",
            "Epoch 211/560\n",
            "2712/2712 [==============================] - 22s 8ms/step - loss: 0.0905 - accuracy: 0.9657\n",
            "Epoch 212/560\n",
            "2712/2712 [==============================] - 22s 8ms/step - loss: 0.0946 - accuracy: 0.9641\n",
            "Epoch 213/560\n",
            "2712/2712 [==============================] - 22s 8ms/step - loss: 0.0904 - accuracy: 0.9657\n",
            "Epoch 214/560\n",
            "2712/2712 [==============================] - 22s 8ms/step - loss: 0.0894 - accuracy: 0.9660\n",
            "Epoch 215/560\n",
            "2712/2712 [==============================] - 22s 8ms/step - loss: 0.0916 - accuracy: 0.9652\n",
            "Epoch 216/560\n",
            "2712/2712 [==============================] - 21s 8ms/step - loss: 0.0924 - accuracy: 0.9647\n",
            "Epoch 217/560\n",
            "2712/2712 [==============================] - 22s 8ms/step - loss: 0.0909 - accuracy: 0.9653\n",
            "Epoch 218/560\n",
            "2712/2712 [==============================] - 21s 8ms/step - loss: 0.0911 - accuracy: 0.9662\n",
            "Epoch 219/560\n",
            "2712/2712 [==============================] - 21s 8ms/step - loss: 0.0924 - accuracy: 0.9651\n",
            "Epoch 220/560\n",
            "2712/2712 [==============================] - 21s 8ms/step - loss: 0.0921 - accuracy: 0.9655\n",
            "Epoch 221/560\n",
            "2712/2712 [==============================] - 21s 8ms/step - loss: 0.0923 - accuracy: 0.9649\n",
            "Epoch 222/560\n",
            "2712/2712 [==============================] - 23s 8ms/step - loss: 0.0919 - accuracy: 0.9659\n",
            "Epoch 223/560\n",
            "2712/2712 [==============================] - 22s 8ms/step - loss: 0.0876 - accuracy: 0.9674\n",
            "Epoch 224/560\n",
            "2712/2712 [==============================] - 22s 8ms/step - loss: 0.0891 - accuracy: 0.9667\n",
            "Epoch 225/560\n",
            "2712/2712 [==============================] - 22s 8ms/step - loss: 0.0901 - accuracy: 0.9657\n",
            "Epoch 226/560\n",
            "2712/2712 [==============================] - 22s 8ms/step - loss: 0.0898 - accuracy: 0.9654\n",
            "Epoch 227/560\n",
            "2712/2712 [==============================] - 20s 7ms/step - loss: 0.0899 - accuracy: 0.9658\n",
            "Epoch 228/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0916 - accuracy: 0.9650\n",
            "Epoch 229/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0885 - accuracy: 0.9664\n",
            "Epoch 230/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0882 - accuracy: 0.9666\n",
            "Epoch 231/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0889 - accuracy: 0.9660\n",
            "Epoch 232/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0882 - accuracy: 0.9664\n",
            "Epoch 233/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0902 - accuracy: 0.9660\n",
            "Epoch 234/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0886 - accuracy: 0.9662\n",
            "Epoch 235/560\n",
            "2712/2712 [==============================] - 21s 8ms/step - loss: 0.0924 - accuracy: 0.9651\n",
            "Epoch 236/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0933 - accuracy: 0.9651\n",
            "Epoch 237/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0917 - accuracy: 0.9648\n",
            "Epoch 238/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0908 - accuracy: 0.9661\n",
            "Epoch 239/560\n",
            "2712/2712 [==============================] - 20s 7ms/step - loss: 0.0920 - accuracy: 0.9660\n",
            "Epoch 240/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0909 - accuracy: 0.9658\n",
            "Epoch 241/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0900 - accuracy: 0.9660\n",
            "Epoch 242/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0875 - accuracy: 0.9667\n",
            "Epoch 243/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0902 - accuracy: 0.9660\n",
            "Epoch 244/560\n",
            "2712/2712 [==============================] - 21s 8ms/step - loss: 0.0911 - accuracy: 0.9658\n",
            "Epoch 245/560\n",
            "2712/2712 [==============================] - 21s 8ms/step - loss: 0.0897 - accuracy: 0.9662\n",
            "Epoch 246/560\n",
            "2712/2712 [==============================] - 22s 8ms/step - loss: 0.0886 - accuracy: 0.9665\n",
            "Epoch 247/560\n",
            "2712/2712 [==============================] - 25s 9ms/step - loss: 0.0901 - accuracy: 0.9654\n",
            "Epoch 248/560\n",
            "2712/2712 [==============================] - 25s 9ms/step - loss: 0.0897 - accuracy: 0.9662\n",
            "Epoch 249/560\n",
            "2712/2712 [==============================] - 25s 9ms/step - loss: 0.0892 - accuracy: 0.9664\n",
            "Epoch 250/560\n",
            "2712/2712 [==============================] - 24s 9ms/step - loss: 0.0879 - accuracy: 0.9672\n",
            "Epoch 251/560\n",
            "2712/2712 [==============================] - 24s 9ms/step - loss: 0.0897 - accuracy: 0.9666\n",
            "Epoch 252/560\n",
            "2712/2712 [==============================] - 24s 9ms/step - loss: 0.0881 - accuracy: 0.9665\n",
            "Epoch 253/560\n",
            "2712/2712 [==============================] - 25s 9ms/step - loss: 0.0910 - accuracy: 0.9659\n",
            "Epoch 254/560\n",
            "2712/2712 [==============================] - 27s 10ms/step - loss: 0.0894 - accuracy: 0.9663\n",
            "Epoch 255/560\n",
            "2712/2712 [==============================] - 30s 11ms/step - loss: 0.0897 - accuracy: 0.9665\n",
            "Epoch 256/560\n",
            "2712/2712 [==============================] - 23s 8ms/step - loss: 0.0916 - accuracy: 0.9656\n",
            "Epoch 257/560\n",
            "2712/2712 [==============================] - 22s 8ms/step - loss: 0.0904 - accuracy: 0.9656\n",
            "Epoch 258/560\n",
            "2712/2712 [==============================] - 21s 8ms/step - loss: 0.0907 - accuracy: 0.9652\n",
            "Epoch 259/560\n",
            "2712/2712 [==============================] - 21s 8ms/step - loss: 0.0888 - accuracy: 0.9662\n",
            "Epoch 260/560\n",
            "2712/2712 [==============================] - 20s 8ms/step - loss: 0.0910 - accuracy: 0.9658\n",
            "Epoch 261/560\n",
            "2712/2712 [==============================] - 23s 9ms/step - loss: 0.0895 - accuracy: 0.9665\n",
            "Epoch 262/560\n",
            "2712/2712 [==============================] - 21s 8ms/step - loss: 0.0878 - accuracy: 0.9663\n",
            "Epoch 263/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0874 - accuracy: 0.9669\n",
            "Epoch 264/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0901 - accuracy: 0.9660\n",
            "Epoch 265/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0905 - accuracy: 0.9652\n",
            "Epoch 266/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0888 - accuracy: 0.9667\n",
            "Epoch 267/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0879 - accuracy: 0.9669\n",
            "Epoch 268/560\n",
            "2712/2712 [==============================] - 21s 8ms/step - loss: 0.0912 - accuracy: 0.9653\n",
            "Epoch 269/560\n",
            "2712/2712 [==============================] - 22s 8ms/step - loss: 0.0877 - accuracy: 0.9669\n",
            "Epoch 270/560\n",
            "2712/2712 [==============================] - 24s 9ms/step - loss: 0.0888 - accuracy: 0.9670\n",
            "Epoch 271/560\n",
            "2712/2712 [==============================] - 20s 7ms/step - loss: 0.0869 - accuracy: 0.9669\n",
            "Epoch 272/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0900 - accuracy: 0.9663\n",
            "Epoch 273/560\n",
            "2712/2712 [==============================] - 18s 7ms/step - loss: 0.0907 - accuracy: 0.9656\n",
            "Epoch 274/560\n",
            "2712/2712 [==============================] - 18s 7ms/step - loss: 0.0915 - accuracy: 0.9657\n",
            "Epoch 275/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0898 - accuracy: 0.9665\n",
            "Epoch 276/560\n",
            "2712/2712 [==============================] - 18s 6ms/step - loss: 0.0931 - accuracy: 0.9648\n",
            "Epoch 277/560\n",
            "2712/2712 [==============================] - 18s 7ms/step - loss: 0.0895 - accuracy: 0.9662\n",
            "Epoch 278/560\n",
            "2712/2712 [==============================] - 18s 7ms/step - loss: 0.0884 - accuracy: 0.9667\n",
            "Epoch 279/560\n",
            "2712/2712 [==============================] - 18s 7ms/step - loss: 0.0877 - accuracy: 0.9675\n",
            "Epoch 280/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0905 - accuracy: 0.9660\n",
            "Epoch 281/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0878 - accuracy: 0.9668\n",
            "Epoch 282/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0865 - accuracy: 0.9668\n",
            "Epoch 283/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0879 - accuracy: 0.9663\n",
            "Epoch 284/560\n",
            "2712/2712 [==============================] - 18s 7ms/step - loss: 0.0902 - accuracy: 0.9658\n",
            "Epoch 285/560\n",
            "2712/2712 [==============================] - 20s 7ms/step - loss: 0.0879 - accuracy: 0.9663\n",
            "Epoch 286/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0893 - accuracy: 0.9663\n",
            "Epoch 287/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0845 - accuracy: 0.9683\n",
            "Epoch 288/560\n",
            "2712/2712 [==============================] - 18s 7ms/step - loss: 0.0857 - accuracy: 0.9674\n",
            "Epoch 289/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0882 - accuracy: 0.9662\n",
            "Epoch 290/560\n",
            "2712/2712 [==============================] - 18s 7ms/step - loss: 0.0920 - accuracy: 0.9656\n",
            "Epoch 291/560\n",
            "2712/2712 [==============================] - 18s 7ms/step - loss: 0.0896 - accuracy: 0.9661\n",
            "Epoch 292/560\n",
            "2712/2712 [==============================] - 18s 7ms/step - loss: 0.0856 - accuracy: 0.9677\n",
            "Epoch 293/560\n",
            "2712/2712 [==============================] - 18s 6ms/step - loss: 0.0877 - accuracy: 0.9664\n",
            "Epoch 294/560\n",
            "2712/2712 [==============================] - 18s 7ms/step - loss: 0.0903 - accuracy: 0.9664\n",
            "Epoch 295/560\n",
            "2712/2712 [==============================] - 18s 7ms/step - loss: 0.0862 - accuracy: 0.9674\n",
            "Epoch 296/560\n",
            "2712/2712 [==============================] - 18s 7ms/step - loss: 0.0900 - accuracy: 0.9659\n",
            "Epoch 297/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0884 - accuracy: 0.9662\n",
            "Epoch 298/560\n",
            "2712/2712 [==============================] - 18s 7ms/step - loss: 0.0852 - accuracy: 0.9675\n",
            "Epoch 299/560\n",
            "2712/2712 [==============================] - 18s 6ms/step - loss: 0.0915 - accuracy: 0.9659\n",
            "Epoch 300/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0881 - accuracy: 0.9666\n",
            "Epoch 301/560\n",
            "2712/2712 [==============================] - 18s 7ms/step - loss: 0.0873 - accuracy: 0.9673\n",
            "Epoch 302/560\n",
            "2712/2712 [==============================] - 18s 7ms/step - loss: 0.0876 - accuracy: 0.9667\n",
            "Epoch 303/560\n",
            "2712/2712 [==============================] - 18s 7ms/step - loss: 0.0874 - accuracy: 0.9669\n",
            "Epoch 304/560\n",
            "2712/2712 [==============================] - 18s 7ms/step - loss: 0.0885 - accuracy: 0.9665\n",
            "Epoch 305/560\n",
            "2712/2712 [==============================] - 18s 7ms/step - loss: 0.0866 - accuracy: 0.9672\n",
            "Epoch 306/560\n",
            "2712/2712 [==============================] - 18s 7ms/step - loss: 0.0901 - accuracy: 0.9661\n",
            "Epoch 307/560\n",
            "2712/2712 [==============================] - 18s 7ms/step - loss: 0.0884 - accuracy: 0.9667\n",
            "Epoch 308/560\n",
            "2712/2712 [==============================] - 18s 7ms/step - loss: 0.0890 - accuracy: 0.9662\n",
            "Epoch 309/560\n",
            "2712/2712 [==============================] - 18s 7ms/step - loss: 0.0878 - accuracy: 0.9664\n",
            "Epoch 310/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0871 - accuracy: 0.9672\n",
            "Epoch 311/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0872 - accuracy: 0.9667\n",
            "Epoch 312/560\n",
            "2712/2712 [==============================] - 18s 7ms/step - loss: 0.0883 - accuracy: 0.9666\n",
            "Epoch 313/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0860 - accuracy: 0.9675\n",
            "Epoch 314/560\n",
            "2712/2712 [==============================] - 18s 7ms/step - loss: 0.0908 - accuracy: 0.9652\n",
            "Epoch 315/560\n",
            "2712/2712 [==============================] - 18s 7ms/step - loss: 0.0906 - accuracy: 0.9658\n",
            "Epoch 316/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0858 - accuracy: 0.9673\n",
            "Epoch 317/560\n",
            "2712/2712 [==============================] - 18s 7ms/step - loss: 0.0912 - accuracy: 0.9653\n",
            "Epoch 318/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0900 - accuracy: 0.9656\n",
            "Epoch 319/560\n",
            "2712/2712 [==============================] - 18s 7ms/step - loss: 0.0909 - accuracy: 0.9656\n",
            "Epoch 320/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0896 - accuracy: 0.9666\n",
            "Epoch 321/560\n",
            "2712/2712 [==============================] - 18s 7ms/step - loss: 0.0880 - accuracy: 0.9675\n",
            "Epoch 322/560\n",
            "2712/2712 [==============================] - 18s 7ms/step - loss: 0.0874 - accuracy: 0.9673\n",
            "Epoch 323/560\n",
            "2712/2712 [==============================] - 18s 7ms/step - loss: 0.0866 - accuracy: 0.9673\n",
            "Epoch 324/560\n",
            "2712/2712 [==============================] - 20s 7ms/step - loss: 0.0878 - accuracy: 0.9667\n",
            "Epoch 325/560\n",
            "2712/2712 [==============================] - 18s 7ms/step - loss: 0.0888 - accuracy: 0.9661\n",
            "Epoch 326/560\n",
            "2712/2712 [==============================] - 18s 7ms/step - loss: 0.0895 - accuracy: 0.9669\n",
            "Epoch 327/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0890 - accuracy: 0.9663\n",
            "Epoch 328/560\n",
            "2712/2712 [==============================] - 18s 7ms/step - loss: 0.0891 - accuracy: 0.9664\n",
            "Epoch 329/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0885 - accuracy: 0.9666\n",
            "Epoch 330/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0880 - accuracy: 0.9668\n",
            "Epoch 331/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0895 - accuracy: 0.9661\n",
            "Epoch 332/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0896 - accuracy: 0.9659\n",
            "Epoch 333/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0883 - accuracy: 0.9667\n",
            "Epoch 334/560\n",
            "2712/2712 [==============================] - 20s 7ms/step - loss: 0.0881 - accuracy: 0.9671\n",
            "Epoch 335/560\n",
            "2712/2712 [==============================] - 20s 7ms/step - loss: 0.0858 - accuracy: 0.9673\n",
            "Epoch 336/560\n",
            "2712/2712 [==============================] - 20s 7ms/step - loss: 0.0871 - accuracy: 0.9673\n",
            "Epoch 337/560\n",
            "2712/2712 [==============================] - 21s 8ms/step - loss: 0.0868 - accuracy: 0.9670\n",
            "Epoch 338/560\n",
            "2712/2712 [==============================] - 20s 7ms/step - loss: 0.0880 - accuracy: 0.9662\n",
            "Epoch 339/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0874 - accuracy: 0.9670\n",
            "Epoch 340/560\n",
            "2712/2712 [==============================] - 21s 8ms/step - loss: 0.0892 - accuracy: 0.9661\n",
            "Epoch 341/560\n",
            "2712/2712 [==============================] - 21s 8ms/step - loss: 0.0910 - accuracy: 0.9650\n",
            "Epoch 342/560\n",
            "2712/2712 [==============================] - 21s 8ms/step - loss: 0.0903 - accuracy: 0.9663\n",
            "Epoch 343/560\n",
            "2712/2712 [==============================] - 21s 8ms/step - loss: 0.0874 - accuracy: 0.9672\n",
            "Epoch 344/560\n",
            "2712/2712 [==============================] - 21s 8ms/step - loss: 0.0857 - accuracy: 0.9674\n",
            "Epoch 345/560\n",
            "2712/2712 [==============================] - 20s 7ms/step - loss: 0.0879 - accuracy: 0.9664\n",
            "Epoch 346/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0885 - accuracy: 0.9667\n",
            "Epoch 347/560\n",
            "2712/2712 [==============================] - 20s 7ms/step - loss: 0.0853 - accuracy: 0.9682\n",
            "Epoch 348/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0889 - accuracy: 0.9665\n",
            "Epoch 349/560\n",
            "2712/2712 [==============================] - 20s 7ms/step - loss: 0.0869 - accuracy: 0.9670\n",
            "Epoch 350/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0838 - accuracy: 0.9685\n",
            "Epoch 351/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0896 - accuracy: 0.9661\n",
            "Epoch 352/560\n",
            "2712/2712 [==============================] - 18s 7ms/step - loss: 0.0882 - accuracy: 0.9666\n",
            "Epoch 353/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0897 - accuracy: 0.9659\n",
            "Epoch 354/560\n",
            "2712/2712 [==============================] - 18s 7ms/step - loss: 0.0882 - accuracy: 0.9670\n",
            "Epoch 355/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0856 - accuracy: 0.9673\n",
            "Epoch 356/560\n",
            "2712/2712 [==============================] - 18s 7ms/step - loss: 0.0874 - accuracy: 0.9663\n",
            "Epoch 357/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0872 - accuracy: 0.9674\n",
            "Epoch 358/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0860 - accuracy: 0.9673\n",
            "Epoch 359/560\n",
            "2712/2712 [==============================] - 18s 7ms/step - loss: 0.0911 - accuracy: 0.9653\n",
            "Epoch 360/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0874 - accuracy: 0.9670\n",
            "Epoch 361/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0878 - accuracy: 0.9665\n",
            "Epoch 362/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0865 - accuracy: 0.9679\n",
            "Epoch 363/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0863 - accuracy: 0.9673\n",
            "Epoch 364/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0851 - accuracy: 0.9681\n",
            "Epoch 365/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0868 - accuracy: 0.9670\n",
            "Epoch 366/560\n",
            "2712/2712 [==============================] - 20s 7ms/step - loss: 0.0872 - accuracy: 0.9669\n",
            "Epoch 367/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0844 - accuracy: 0.9683\n",
            "Epoch 368/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0914 - accuracy: 0.9660\n",
            "Epoch 369/560\n",
            "2712/2712 [==============================] - 20s 7ms/step - loss: 0.0874 - accuracy: 0.9669\n",
            "Epoch 370/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0879 - accuracy: 0.9669\n",
            "Epoch 371/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0876 - accuracy: 0.9673\n",
            "Epoch 372/560\n",
            "2712/2712 [==============================] - 20s 7ms/step - loss: 0.0896 - accuracy: 0.9666\n",
            "Epoch 373/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0869 - accuracy: 0.9670\n",
            "Epoch 374/560\n",
            "2712/2712 [==============================] - 20s 7ms/step - loss: 0.0873 - accuracy: 0.9668\n",
            "Epoch 375/560\n",
            "2712/2712 [==============================] - 23s 9ms/step - loss: 0.0885 - accuracy: 0.9664\n",
            "Epoch 376/560\n",
            "2712/2712 [==============================] - 25s 9ms/step - loss: 0.0895 - accuracy: 0.9663\n",
            "Epoch 377/560\n",
            "2712/2712 [==============================] - 25s 9ms/step - loss: 0.0878 - accuracy: 0.9672\n",
            "Epoch 378/560\n",
            "2712/2712 [==============================] - 23s 9ms/step - loss: 0.0901 - accuracy: 0.9666\n",
            "Epoch 379/560\n",
            "2712/2712 [==============================] - 25s 9ms/step - loss: 0.0892 - accuracy: 0.9666\n",
            "Epoch 380/560\n",
            "2712/2712 [==============================] - 24s 9ms/step - loss: 0.0862 - accuracy: 0.9678\n",
            "Epoch 381/560\n",
            "2712/2712 [==============================] - 24s 9ms/step - loss: 0.0849 - accuracy: 0.9683\n",
            "Epoch 382/560\n",
            "2712/2712 [==============================] - 24s 9ms/step - loss: 0.0920 - accuracy: 0.9651\n",
            "Epoch 383/560\n",
            "2712/2712 [==============================] - 23s 8ms/step - loss: 0.0886 - accuracy: 0.9665\n",
            "Epoch 384/560\n",
            "2712/2712 [==============================] - 24s 9ms/step - loss: 0.0892 - accuracy: 0.9665\n",
            "Epoch 385/560\n",
            "2712/2712 [==============================] - 24s 9ms/step - loss: 0.0887 - accuracy: 0.9665\n",
            "Epoch 386/560\n",
            "2712/2712 [==============================] - 23s 8ms/step - loss: 0.0865 - accuracy: 0.9673\n",
            "Epoch 387/560\n",
            "2712/2712 [==============================] - 24s 9ms/step - loss: 0.0853 - accuracy: 0.9678\n",
            "Epoch 388/560\n",
            "2712/2712 [==============================] - 24s 9ms/step - loss: 0.0868 - accuracy: 0.9672\n",
            "Epoch 389/560\n",
            "2712/2712 [==============================] - 25s 9ms/step - loss: 0.0871 - accuracy: 0.9673\n",
            "Epoch 390/560\n",
            "2712/2712 [==============================] - 24s 9ms/step - loss: 0.0859 - accuracy: 0.9674\n",
            "Epoch 391/560\n",
            "2712/2712 [==============================] - 24s 9ms/step - loss: 0.0878 - accuracy: 0.9670\n",
            "Epoch 392/560\n",
            "2712/2712 [==============================] - 24s 9ms/step - loss: 0.0842 - accuracy: 0.9683\n",
            "Epoch 393/560\n",
            "2712/2712 [==============================] - 23s 9ms/step - loss: 0.0902 - accuracy: 0.9657\n",
            "Epoch 394/560\n",
            "2712/2712 [==============================] - 22s 8ms/step - loss: 0.0860 - accuracy: 0.9672\n",
            "Epoch 395/560\n",
            "2712/2712 [==============================] - 22s 8ms/step - loss: 0.0887 - accuracy: 0.9672\n",
            "Epoch 396/560\n",
            "2712/2712 [==============================] - 23s 8ms/step - loss: 0.0892 - accuracy: 0.9667\n",
            "Epoch 397/560\n",
            "2712/2712 [==============================] - 22s 8ms/step - loss: 0.0871 - accuracy: 0.9672\n",
            "Epoch 398/560\n",
            "2712/2712 [==============================] - 22s 8ms/step - loss: 0.0875 - accuracy: 0.9667\n",
            "Epoch 399/560\n",
            "2712/2712 [==============================] - 22s 8ms/step - loss: 0.0871 - accuracy: 0.9664\n",
            "Epoch 400/560\n",
            "2712/2712 [==============================] - 22s 8ms/step - loss: 0.0896 - accuracy: 0.9666\n",
            "Epoch 401/560\n",
            "2712/2712 [==============================] - 23s 9ms/step - loss: 0.0863 - accuracy: 0.9668\n",
            "Epoch 402/560\n",
            "2712/2712 [==============================] - 22s 8ms/step - loss: 0.0877 - accuracy: 0.9669\n",
            "Epoch 403/560\n",
            "2712/2712 [==============================] - 22s 8ms/step - loss: 0.0871 - accuracy: 0.9669\n",
            "Epoch 404/560\n",
            "2712/2712 [==============================] - 23s 9ms/step - loss: 0.0889 - accuracy: 0.9669\n",
            "Epoch 405/560\n",
            "2712/2712 [==============================] - 22s 8ms/step - loss: 0.0892 - accuracy: 0.9662\n",
            "Epoch 406/560\n",
            "2712/2712 [==============================] - 24s 9ms/step - loss: 0.0898 - accuracy: 0.9663\n",
            "Epoch 407/560\n",
            "2712/2712 [==============================] - 22s 8ms/step - loss: 0.0872 - accuracy: 0.9670\n",
            "Epoch 408/560\n",
            "2712/2712 [==============================] - 23s 8ms/step - loss: 0.0876 - accuracy: 0.9670\n",
            "Epoch 409/560\n",
            "2712/2712 [==============================] - 24s 9ms/step - loss: 0.0886 - accuracy: 0.9669\n",
            "Epoch 410/560\n",
            "2712/2712 [==============================] - 23s 8ms/step - loss: 0.0864 - accuracy: 0.9671\n",
            "Epoch 411/560\n",
            "2712/2712 [==============================] - 24s 9ms/step - loss: 0.0862 - accuracy: 0.9675\n",
            "Epoch 412/560\n",
            "2712/2712 [==============================] - 23s 8ms/step - loss: 0.0847 - accuracy: 0.9678\n",
            "Epoch 413/560\n",
            "2712/2712 [==============================] - 23s 8ms/step - loss: 0.0849 - accuracy: 0.9681\n",
            "Epoch 414/560\n",
            "2712/2712 [==============================] - 23s 9ms/step - loss: 0.0859 - accuracy: 0.9674\n",
            "Epoch 415/560\n",
            "2712/2712 [==============================] - 22s 8ms/step - loss: 0.0853 - accuracy: 0.9677\n",
            "Epoch 416/560\n",
            "2712/2712 [==============================] - 23s 9ms/step - loss: 0.0857 - accuracy: 0.9676\n",
            "Epoch 417/560\n",
            "2712/2712 [==============================] - 23s 9ms/step - loss: 0.0862 - accuracy: 0.9675\n",
            "Epoch 418/560\n",
            "2712/2712 [==============================] - 23s 9ms/step - loss: 0.0866 - accuracy: 0.9678\n",
            "Epoch 419/560\n",
            "2712/2712 [==============================] - 24s 9ms/step - loss: 0.0873 - accuracy: 0.9673\n",
            "Epoch 420/560\n",
            "2712/2712 [==============================] - 24s 9ms/step - loss: 0.0858 - accuracy: 0.9680\n",
            "Epoch 421/560\n",
            "2712/2712 [==============================] - 24s 9ms/step - loss: 0.0866 - accuracy: 0.9671\n",
            "Epoch 422/560\n",
            "2712/2712 [==============================] - 24s 9ms/step - loss: 0.0869 - accuracy: 0.9670\n",
            "Epoch 423/560\n",
            "2712/2712 [==============================] - 25s 9ms/step - loss: 0.0874 - accuracy: 0.9670\n",
            "Epoch 424/560\n",
            "2712/2712 [==============================] - 24s 9ms/step - loss: 0.0855 - accuracy: 0.9677\n",
            "Epoch 425/560\n",
            "2712/2712 [==============================] - 24s 9ms/step - loss: 0.0894 - accuracy: 0.9665\n",
            "Epoch 426/560\n",
            "2712/2712 [==============================] - 25s 9ms/step - loss: 0.0876 - accuracy: 0.9665\n",
            "Epoch 427/560\n",
            "2712/2712 [==============================] - 24s 9ms/step - loss: 0.0881 - accuracy: 0.9669\n",
            "Epoch 428/560\n",
            "2712/2712 [==============================] - 25s 9ms/step - loss: 0.0865 - accuracy: 0.9672\n",
            "Epoch 429/560\n",
            "2712/2712 [==============================] - 25s 9ms/step - loss: 0.0856 - accuracy: 0.9681\n",
            "Epoch 430/560\n",
            "2712/2712 [==============================] - 25s 9ms/step - loss: 0.0847 - accuracy: 0.9681\n",
            "Epoch 431/560\n",
            "2712/2712 [==============================] - 26s 9ms/step - loss: 0.0882 - accuracy: 0.9664\n",
            "Epoch 432/560\n",
            "2712/2712 [==============================] - 24s 9ms/step - loss: 0.0889 - accuracy: 0.9660\n",
            "Epoch 433/560\n",
            "2712/2712 [==============================] - 25s 9ms/step - loss: 0.0862 - accuracy: 0.9674\n",
            "Epoch 434/560\n",
            "2712/2712 [==============================] - 24s 9ms/step - loss: 0.0869 - accuracy: 0.9669\n",
            "Epoch 435/560\n",
            "2712/2712 [==============================] - 24s 9ms/step - loss: 0.0877 - accuracy: 0.9669\n",
            "Epoch 436/560\n",
            "2712/2712 [==============================] - 26s 10ms/step - loss: 0.0878 - accuracy: 0.9662\n",
            "Epoch 437/560\n",
            "2712/2712 [==============================] - 24s 9ms/step - loss: 0.0839 - accuracy: 0.9685\n",
            "Epoch 438/560\n",
            "2712/2712 [==============================] - 25s 9ms/step - loss: 0.0854 - accuracy: 0.9677\n",
            "Epoch 439/560\n",
            "2712/2712 [==============================] - 24s 9ms/step - loss: 0.0877 - accuracy: 0.9668\n",
            "Epoch 440/560\n",
            "2712/2712 [==============================] - 24s 9ms/step - loss: 0.0894 - accuracy: 0.9663\n",
            "Epoch 441/560\n",
            "2712/2712 [==============================] - 25s 9ms/step - loss: 0.0881 - accuracy: 0.9674\n",
            "Epoch 442/560\n",
            "2712/2712 [==============================] - 24s 9ms/step - loss: 0.0855 - accuracy: 0.9676\n",
            "Epoch 443/560\n",
            "2712/2712 [==============================] - 25s 9ms/step - loss: 0.0907 - accuracy: 0.9654\n",
            "Epoch 444/560\n",
            "2712/2712 [==============================] - 24s 9ms/step - loss: 0.0894 - accuracy: 0.9663\n",
            "Epoch 445/560\n",
            "2712/2712 [==============================] - 24s 9ms/step - loss: 0.0891 - accuracy: 0.9666\n",
            "Epoch 446/560\n",
            "2712/2712 [==============================] - 25s 9ms/step - loss: 0.0877 - accuracy: 0.9667\n",
            "Epoch 447/560\n",
            "2712/2712 [==============================] - 23s 8ms/step - loss: 0.0836 - accuracy: 0.9689\n",
            "Epoch 448/560\n",
            "2712/2712 [==============================] - 24s 9ms/step - loss: 0.0860 - accuracy: 0.9673\n",
            "Epoch 449/560\n",
            "2712/2712 [==============================] - 25s 9ms/step - loss: 0.0850 - accuracy: 0.9681\n",
            "Epoch 450/560\n",
            "2712/2712 [==============================] - 23s 9ms/step - loss: 0.0862 - accuracy: 0.9673\n",
            "Epoch 451/560\n",
            "2712/2712 [==============================] - 25s 9ms/step - loss: 0.0872 - accuracy: 0.9673\n",
            "Epoch 452/560\n",
            "2712/2712 [==============================] - 23s 8ms/step - loss: 0.0868 - accuracy: 0.9677\n",
            "Epoch 453/560\n",
            "2712/2712 [==============================] - 23s 8ms/step - loss: 0.0886 - accuracy: 0.9669\n",
            "Epoch 454/560\n",
            "2712/2712 [==============================] - 24s 9ms/step - loss: 0.0855 - accuracy: 0.9677\n",
            "Epoch 455/560\n",
            "2712/2712 [==============================] - 22s 8ms/step - loss: 0.0865 - accuracy: 0.9677\n",
            "Epoch 456/560\n",
            "2712/2712 [==============================] - 22s 8ms/step - loss: 0.0855 - accuracy: 0.9676\n",
            "Epoch 457/560\n",
            "2712/2712 [==============================] - 22s 8ms/step - loss: 0.0895 - accuracy: 0.9658\n",
            "Epoch 458/560\n",
            "2712/2712 [==============================] - 21s 8ms/step - loss: 0.0856 - accuracy: 0.9671\n",
            "Epoch 459/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0872 - accuracy: 0.9674\n",
            "Epoch 460/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0862 - accuracy: 0.9672\n",
            "Epoch 461/560\n",
            "2712/2712 [==============================] - 20s 7ms/step - loss: 0.0837 - accuracy: 0.9684\n",
            "Epoch 462/560\n",
            "2712/2712 [==============================] - 20s 7ms/step - loss: 0.0880 - accuracy: 0.9663\n",
            "Epoch 463/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0862 - accuracy: 0.9675\n",
            "Epoch 464/560\n",
            "2712/2712 [==============================] - 20s 7ms/step - loss: 0.0888 - accuracy: 0.9665\n",
            "Epoch 465/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0853 - accuracy: 0.9677\n",
            "Epoch 466/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0870 - accuracy: 0.9672\n",
            "Epoch 467/560\n",
            "2712/2712 [==============================] - 20s 7ms/step - loss: 0.0846 - accuracy: 0.9678\n",
            "Epoch 468/560\n",
            "2712/2712 [==============================] - 20s 7ms/step - loss: 0.0884 - accuracy: 0.9668\n",
            "Epoch 469/560\n",
            "2712/2712 [==============================] - 20s 7ms/step - loss: 0.0862 - accuracy: 0.9680\n",
            "Epoch 470/560\n",
            "2712/2712 [==============================] - 22s 8ms/step - loss: 0.0857 - accuracy: 0.9684\n",
            "Epoch 471/560\n",
            "2712/2712 [==============================] - 20s 7ms/step - loss: 0.0879 - accuracy: 0.9669\n",
            "Epoch 472/560\n",
            "2712/2712 [==============================] - 20s 7ms/step - loss: 0.0883 - accuracy: 0.9668\n",
            "Epoch 473/560\n",
            "2712/2712 [==============================] - 21s 8ms/step - loss: 0.0892 - accuracy: 0.9662\n",
            "Epoch 474/560\n",
            "2712/2712 [==============================] - 20s 7ms/step - loss: 0.0887 - accuracy: 0.9673\n",
            "Epoch 475/560\n",
            "2712/2712 [==============================] - 20s 7ms/step - loss: 0.0885 - accuracy: 0.9675\n",
            "Epoch 476/560\n",
            "2712/2712 [==============================] - 21s 8ms/step - loss: 0.0842 - accuracy: 0.9684\n",
            "Epoch 477/560\n",
            "2712/2712 [==============================] - 21s 8ms/step - loss: 0.0844 - accuracy: 0.9682\n",
            "Epoch 478/560\n",
            "2712/2712 [==============================] - 20s 8ms/step - loss: 0.0875 - accuracy: 0.9671\n",
            "Epoch 479/560\n",
            "2712/2712 [==============================] - 22s 8ms/step - loss: 0.0857 - accuracy: 0.9671\n",
            "Epoch 480/560\n",
            "2712/2712 [==============================] - 20s 7ms/step - loss: 0.0853 - accuracy: 0.9688\n",
            "Epoch 481/560\n",
            "2712/2712 [==============================] - 21s 8ms/step - loss: 0.0843 - accuracy: 0.9682\n",
            "Epoch 482/560\n",
            "2712/2712 [==============================] - 20s 7ms/step - loss: 0.0861 - accuracy: 0.9679\n",
            "Epoch 483/560\n",
            "2712/2712 [==============================] - 20s 7ms/step - loss: 0.0903 - accuracy: 0.9657\n",
            "Epoch 484/560\n",
            "2712/2712 [==============================] - 21s 8ms/step - loss: 0.0888 - accuracy: 0.9671\n",
            "Epoch 485/560\n",
            "2712/2712 [==============================] - 21s 8ms/step - loss: 0.0885 - accuracy: 0.9670\n",
            "Epoch 486/560\n",
            "2712/2712 [==============================] - 21s 8ms/step - loss: 0.0853 - accuracy: 0.9678\n",
            "Epoch 487/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0858 - accuracy: 0.9670\n",
            "Epoch 488/560\n",
            "2712/2712 [==============================] - 20s 7ms/step - loss: 0.0845 - accuracy: 0.9680\n",
            "Epoch 489/560\n",
            "2712/2712 [==============================] - 22s 8ms/step - loss: 0.0839 - accuracy: 0.9686\n",
            "Epoch 490/560\n",
            "2712/2712 [==============================] - 20s 7ms/step - loss: 0.0860 - accuracy: 0.9677\n",
            "Epoch 491/560\n",
            "2712/2712 [==============================] - 21s 8ms/step - loss: 0.0860 - accuracy: 0.9672\n",
            "Epoch 492/560\n",
            "2712/2712 [==============================] - 22s 8ms/step - loss: 0.0858 - accuracy: 0.9675\n",
            "Epoch 493/560\n",
            "2712/2712 [==============================] - 20s 7ms/step - loss: 0.0896 - accuracy: 0.9665\n",
            "Epoch 494/560\n",
            "2712/2712 [==============================] - 20s 7ms/step - loss: 0.0837 - accuracy: 0.9688\n",
            "Epoch 495/560\n",
            "2712/2712 [==============================] - 21s 8ms/step - loss: 0.0852 - accuracy: 0.9682\n",
            "Epoch 496/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0874 - accuracy: 0.9668\n",
            "Epoch 497/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0852 - accuracy: 0.9680\n",
            "Epoch 498/560\n",
            "2712/2712 [==============================] - 20s 7ms/step - loss: 0.0880 - accuracy: 0.9671\n",
            "Epoch 499/560\n",
            "2712/2712 [==============================] - 20s 7ms/step - loss: 0.0874 - accuracy: 0.9674\n",
            "Epoch 500/560\n",
            "2712/2712 [==============================] - 20s 7ms/step - loss: 0.0854 - accuracy: 0.9680\n",
            "Epoch 501/560\n",
            "2712/2712 [==============================] - 21s 8ms/step - loss: 0.0845 - accuracy: 0.9682\n",
            "Epoch 502/560\n",
            "2712/2712 [==============================] - 21s 8ms/step - loss: 0.0880 - accuracy: 0.9662\n",
            "Epoch 503/560\n",
            "2712/2712 [==============================] - 22s 8ms/step - loss: 0.0848 - accuracy: 0.9679\n",
            "Epoch 504/560\n",
            "2712/2712 [==============================] - 22s 8ms/step - loss: 0.0885 - accuracy: 0.9672\n",
            "Epoch 505/560\n",
            "2712/2712 [==============================] - 23s 9ms/step - loss: 0.0875 - accuracy: 0.9674\n",
            "Epoch 506/560\n",
            "2712/2712 [==============================] - 22s 8ms/step - loss: 0.0865 - accuracy: 0.9676\n",
            "Epoch 507/560\n",
            "2712/2712 [==============================] - 24s 9ms/step - loss: 0.0890 - accuracy: 0.9668\n",
            "Epoch 508/560\n",
            "2712/2712 [==============================] - 23s 8ms/step - loss: 0.0892 - accuracy: 0.9660\n",
            "Epoch 509/560\n",
            "2712/2712 [==============================] - 23s 8ms/step - loss: 0.0866 - accuracy: 0.9678\n",
            "Epoch 510/560\n",
            "2712/2712 [==============================] - 23s 9ms/step - loss: 0.0862 - accuracy: 0.9677\n",
            "Epoch 511/560\n",
            "2712/2712 [==============================] - 23s 8ms/step - loss: 0.0909 - accuracy: 0.9667\n",
            "Epoch 512/560\n",
            "2712/2712 [==============================] - 24s 9ms/step - loss: 0.0882 - accuracy: 0.9667\n",
            "Epoch 513/560\n",
            "2712/2712 [==============================] - 27s 10ms/step - loss: 0.0847 - accuracy: 0.9680\n",
            "Epoch 514/560\n",
            "2712/2712 [==============================] - 24s 9ms/step - loss: 0.0870 - accuracy: 0.9673\n",
            "Epoch 515/560\n",
            "2712/2712 [==============================] - 22s 8ms/step - loss: 0.0869 - accuracy: 0.9679\n",
            "Epoch 516/560\n",
            "2712/2712 [==============================] - 24s 9ms/step - loss: 0.0859 - accuracy: 0.9678\n",
            "Epoch 517/560\n",
            "2712/2712 [==============================] - 22s 8ms/step - loss: 0.0856 - accuracy: 0.9675\n",
            "Epoch 518/560\n",
            "2712/2712 [==============================] - 21s 8ms/step - loss: 0.0855 - accuracy: 0.9683\n",
            "Epoch 519/560\n",
            "2712/2712 [==============================] - 22s 8ms/step - loss: 0.0850 - accuracy: 0.9678\n",
            "Epoch 520/560\n",
            "2712/2712 [==============================] - 20s 7ms/step - loss: 0.0875 - accuracy: 0.9677\n",
            "Epoch 521/560\n",
            "2712/2712 [==============================] - 20s 7ms/step - loss: 0.0833 - accuracy: 0.9686\n",
            "Epoch 522/560\n",
            "2712/2712 [==============================] - 20s 8ms/step - loss: 0.0856 - accuracy: 0.9679\n",
            "Epoch 523/560\n",
            "2712/2712 [==============================] - 21s 8ms/step - loss: 0.0857 - accuracy: 0.9686\n",
            "Epoch 524/560\n",
            "2712/2712 [==============================] - 19s 7ms/step - loss: 0.0906 - accuracy: 0.9660\n",
            "Epoch 525/560\n",
            "2712/2712 [==============================] - 20s 7ms/step - loss: 0.0842 - accuracy: 0.9681\n",
            "Epoch 526/560\n",
            "2712/2712 [==============================] - 22s 8ms/step - loss: 0.0860 - accuracy: 0.9678\n",
            "Epoch 527/560\n",
            "2712/2712 [==============================] - 20s 7ms/step - loss: 0.0905 - accuracy: 0.9665\n",
            "Epoch 528/560\n",
            "2712/2712 [==============================] - 20s 7ms/step - loss: 0.0858 - accuracy: 0.9676\n",
            "Epoch 529/560\n",
            "2712/2712 [==============================] - 20s 8ms/step - loss: 0.0860 - accuracy: 0.9677\n",
            "Epoch 530/560\n",
            "2712/2712 [==============================] - 21s 8ms/step - loss: 0.0875 - accuracy: 0.9676\n",
            "Epoch 531/560\n",
            "2712/2712 [==============================] - 20s 7ms/step - loss: 0.0882 - accuracy: 0.9668\n",
            "Epoch 532/560\n",
            "2712/2712 [==============================] - 20s 7ms/step - loss: 0.0854 - accuracy: 0.9676\n",
            "Epoch 533/560\n",
            "2712/2712 [==============================] - 23s 8ms/step - loss: 0.0887 - accuracy: 0.9668\n",
            "Epoch 534/560\n",
            "2712/2712 [==============================] - 21s 8ms/step - loss: 0.0859 - accuracy: 0.9675\n",
            "Epoch 535/560\n",
            "2712/2712 [==============================] - 21s 8ms/step - loss: 0.0897 - accuracy: 0.9662\n",
            "Epoch 536/560\n",
            "2712/2712 [==============================] - 22s 8ms/step - loss: 0.0844 - accuracy: 0.9679\n",
            "Epoch 537/560\n",
            "2712/2712 [==============================] - 20s 7ms/step - loss: 0.0869 - accuracy: 0.9674\n",
            "Epoch 538/560\n",
            "2712/2712 [==============================] - 20s 7ms/step - loss: 0.0860 - accuracy: 0.9677\n",
            "Epoch 539/560\n",
            "2712/2712 [==============================] - 20s 7ms/step - loss: 0.0882 - accuracy: 0.9669\n",
            "Epoch 540/560\n",
            "2712/2712 [==============================] - 22s 8ms/step - loss: 0.0877 - accuracy: 0.9668\n",
            "Epoch 541/560\n",
            "2712/2712 [==============================] - 21s 8ms/step - loss: 0.0824 - accuracy: 0.9691\n",
            "Epoch 542/560\n",
            "2712/2712 [==============================] - 21s 8ms/step - loss: 0.0835 - accuracy: 0.9687\n",
            "Epoch 543/560\n",
            "2712/2712 [==============================] - 22s 8ms/step - loss: 0.0823 - accuracy: 0.9691\n",
            "Epoch 544/560\n",
            "2712/2712 [==============================] - 22s 8ms/step - loss: 0.0861 - accuracy: 0.9676\n",
            "Epoch 545/560\n",
            "2712/2712 [==============================] - 23s 8ms/step - loss: 0.0840 - accuracy: 0.9682\n",
            "Epoch 546/560\n",
            "2712/2712 [==============================] - 25s 9ms/step - loss: 0.0864 - accuracy: 0.9679\n",
            "Epoch 547/560\n",
            "2712/2712 [==============================] - 22s 8ms/step - loss: 0.0861 - accuracy: 0.9678\n",
            "Epoch 548/560\n",
            "2712/2712 [==============================] - 21s 8ms/step - loss: 0.0846 - accuracy: 0.9683\n",
            "Epoch 549/560\n",
            "2712/2712 [==============================] - 23s 8ms/step - loss: 0.0834 - accuracy: 0.9688\n",
            "Epoch 550/560\n",
            "2712/2712 [==============================] - 22s 8ms/step - loss: 0.0876 - accuracy: 0.9669\n",
            "Epoch 551/560\n",
            "2712/2712 [==============================] - 23s 8ms/step - loss: 0.0859 - accuracy: 0.9680\n",
            "Epoch 552/560\n",
            "2712/2712 [==============================] - 24s 9ms/step - loss: 0.0833 - accuracy: 0.9691\n",
            "Epoch 553/560\n",
            "2712/2712 [==============================] - 22s 8ms/step - loss: 0.0828 - accuracy: 0.9692\n",
            "Epoch 554/560\n",
            "2712/2712 [==============================] - 22s 8ms/step - loss: 0.0844 - accuracy: 0.9681\n",
            "Epoch 555/560\n",
            "2712/2712 [==============================] - 21s 8ms/step - loss: 0.0870 - accuracy: 0.9673\n",
            "Epoch 556/560\n",
            "2712/2712 [==============================] - 22s 8ms/step - loss: 0.0872 - accuracy: 0.9672\n",
            "Epoch 557/560\n",
            "2712/2712 [==============================] - 20s 7ms/step - loss: 0.0853 - accuracy: 0.9678\n",
            "Epoch 558/560\n",
            "2712/2712 [==============================] - 20s 7ms/step - loss: 0.0870 - accuracy: 0.9678\n",
            "Epoch 559/560\n",
            "2712/2712 [==============================] - 22s 8ms/step - loss: 0.0850 - accuracy: 0.9678\n",
            "Epoch 560/560\n",
            "2712/2712 [==============================] - 20s 7ms/step - loss: 0.0857 - accuracy: 0.9680\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1a31cc1c50>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "3itZB-Rc7ri7",
        "outputId": "0dfe16f4-2147-4170-806d-98c8bbaa38d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "678/678 [==============================] - 2s 4ms/step - loss: 1.5923 - accuracy: 0.7453\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.5922640562057495, 0.7453321814537048]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "model.evaluate(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Confusion Matrix"
      ],
      "metadata": {
        "id": "HxpfDtWKbOPu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "zW7SM71J7rkT"
      },
      "outputs": [],
      "source": [
        "y_predicted = model.predict(X_test)\n",
        "y_predicted_labels = [np.argmax(i) for i in y_predicted]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "print(confusion_matrix(y_test, y_predicted_labels))\n",
        "print(classification_report(y_test,y_predicted_labels))\n",
        "print(\"Accurecy: \",accuracy_score(y_test, y_predicted_labels))"
      ],
      "metadata": {
        "id": "hPbDM_U8sVLw",
        "outputId": "c657b314-1839-4f85-8e6d-85bd98237f13",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 864  629   25  341  509]\n",
            " [ 393 6278  671  380  169]\n",
            " [  21  871 3329   12   21]\n",
            " [ 281  428   23 2572   70]\n",
            " [ 393  197   23   67 3124]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.44      0.36      0.40      2368\n",
            "           1       0.75      0.80      0.77      7891\n",
            "           2       0.82      0.78      0.80      4254\n",
            "           3       0.76      0.76      0.76      3374\n",
            "           4       0.80      0.82      0.81      3804\n",
            "\n",
            "    accuracy                           0.75     21691\n",
            "   macro avg       0.71      0.71      0.71     21691\n",
            "weighted avg       0.74      0.75      0.74     21691\n",
            "\n",
            "Accurecy:  0.7453321654142271\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def confusion_details(y_test,y_pred):\n",
        "    labels = list(set(y_test))\n",
        "    labels.sort()\n",
        "\n",
        "    print(\"Total labels: %s -> %s\" % (len(labels), labels))\n",
        "\n",
        "    df = pd.DataFrame(\n",
        "        data=confusion_matrix(y_test, y_pred, labels=labels),\n",
        "        columns=labels,\n",
        "        index=labels\n",
        "    )\n",
        "\n",
        "    print(df)\n",
        "\n",
        "    print()\n",
        "    print(\"----------------------------------------------------------------------------------------\")\n",
        "    print(\"----------------------------------------------------------------------------------------\")\n",
        "    print()\n",
        "    #\n",
        "    # Local (metrics per class)\n",
        "    #\n",
        "    tps = {}\n",
        "    fps = {}\n",
        "    fns = {}\n",
        "    tns = {}\n",
        "\n",
        "    precision_local = {}\n",
        "    recall_local = {}\n",
        "    f1_local = {}\n",
        "    accuracy_local = {}\n",
        "    specificity_local={}\n",
        "\n",
        "    for label in labels:\n",
        "        tps[label] = df.loc[label, label]\n",
        "        fps[label] = df[label].sum() - tps[label]\n",
        "        fns[label] = df.loc[label].sum() - tps[label]\n",
        "        tns[label]=len(y_test) - (tps[label] + fps[label] + fns[label])\n",
        "        \n",
        "        tp, fp, fn, tn = tps[label], fps[label], fns[label], tns[label]\n",
        "        \n",
        "        precision_local[label] = tp / (tp + fp) if (tp + fp) > 0. else 0.\n",
        "        specificity_local[label] = tn / (tn + fp) if (tn + fp) > 0. else 0.\n",
        "        recall_local[label] = tp / (tp + fn) if (tp + fp) > 0. else 0.\n",
        "        p, r = precision_local[label], recall_local[label]\n",
        "        \n",
        "        f1_local[label] = 2. * p * r / (p + r) if (p + r) > 0. else 0.\n",
        "        accuracy_local[label] = tp / (tp + fp + fn) if (tp + fp + fn) > 0. else 0.\n",
        "\n",
        "\n",
        "\n",
        "    print(\"#-- Local measures --#\")\n",
        "    print(\"True Positives(TP):\", tps)\n",
        "    print(\"False Positives(FP):\", fps)\n",
        "    print(\"True Negatives(TN):\", tns)\n",
        "    print(\"False Negatives(FN):\", fns)\n",
        "    print(\"----------------------------\")\n",
        "\n",
        "    print(\"Precision:\", precision_local)\n",
        "    print(\"Recall/Sensitivity:\", recall_local)\n",
        "    print(\"Specificity:\",specificity_local)\n",
        "    print(\"F1-Score:\", f1_local)\n",
        "    print(\"Accuracy:\", accuracy_local)\n",
        "\n",
        "\n",
        "    print()\n",
        "    print(\"----------------------------------------------------------------------------------------\")\n",
        "    print(\"----------------------------------------------------------------------------------------\")\n",
        "    print()\n",
        "    #\n",
        "    # Global\n",
        "    #\n",
        "    micro_averages = {}\n",
        "    macro_averages = {}\n",
        "\n",
        "    correct_predictions = sum(tps.values())\n",
        "    true_negative=sum(tns.values())\n",
        "\n",
        "    den = sum(list(tps.values()) + list(fps.values()))\n",
        "    micro_averages[\"Precision\"] = 1. * correct_predictions / den if den > 0. else 0.\n",
        "\n",
        "    den = sum(list(tps.values()) + list(fns.values()))\n",
        "    micro_averages[\"Recall\"] = 1. * correct_predictions / den if den > 0. else 0.\n",
        "\n",
        "    den = sum(list(tns.values()) + list(fps.values()))\n",
        "    micro_averages[\"Specificity\"] = 1. * true_negative / den if den > 0. else 0.\n",
        "\n",
        "\n",
        "    micro_avg_p, micro_avg_r = micro_averages[\"Precision\"], micro_averages[\"Recall\"]\n",
        "    micro_averages[\"F1-score\"] = 2. * micro_avg_p * micro_avg_r / (micro_avg_p + micro_avg_r) if (micro_avg_p + micro_avg_r) > 0. else 0.\n",
        "\n",
        "    macro_averages[\"Precision\"] = np.mean(list(precision_local.values()))\n",
        "    macro_averages[\"Recall\"] = np.mean(list(recall_local.values()))\n",
        "    macro_averages[\"Specificity\"]=np.mean(list(specificity_local.values()))\n",
        "\n",
        "\n",
        "    macro_avg_p, macro_avg_r = macro_averages[\"Precision\"], macro_averages[\"Recall\"]\n",
        "    macro_averages[\"F1-Score\"] = 2. * macro_avg_p * macro_avg_r / (macro_avg_p + macro_avg_r) if (macro_avg_p + macro_avg_r) > 0. else 0.\n",
        "\n",
        "    total_predictions = df.values.sum()\n",
        "    accuracy_global = correct_predictions / total_predictions if total_predictions > 0. else 0.\n",
        "\n",
        "    print(\"#-- Global measures --#\")\n",
        "    print(\"Micro-Averages:\", micro_averages)\n",
        "    print(\"Macro-Averages:\", macro_averages)\n",
        "    print(\"Correct predictions:\", correct_predictions)\n",
        "    print(\"Total predictions:\", total_predictions)\n",
        "    print(\"Accuracy:\", accuracy_global)\n",
        "\n",
        "\n",
        "    print()\n",
        "    print(\"----------------------------------------------------------------------------------------\")\n",
        "    print(\"----------------------------------------------------------------------------------------\")\n",
        "    print()\n",
        "\n",
        "\n",
        "\n",
        "    accuracy_local_new = {}\n",
        "    for label in labels:\n",
        "        tp, fp, fn, tn = tps[label], fps[label], fns[label], tns[label]\n",
        "        accuracy_local_new[label] = (tp + tn) / (tp + fp + fn + tn) if (tp + fp + fn + tn) > 0. else 0.\n",
        "\n",
        "    total_true = sum(list(tps.values()) + list(tns.values()))\n",
        "    total_predictions = sum(list(tps.values()) + list(tns.values()) + list(fps.values()) + list(fns.values()))\n",
        "    accuracy_global_new = 1. * total_true / total_predictions if total_predictions > 0. else 0.\n",
        "\n",
        "    print(\"Accuracy (per class), with TNs:\", accuracy_local_new)\n",
        "    print(\"Accuracy (per class), without TNs:\", accuracy_local)\n",
        "    print(\"Accuracy (global), with TNs:\", accuracy_global_new)\n",
        "    print(\"Accuracy (global), without TNs:\", accuracy_global)"
      ],
      "metadata": {
        "id": "gn79ViJfK94U"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_details(y_test,y_predicted_labels)"
      ],
      "metadata": {
        "id": "QtQUBjA-LZBU",
        "outputId": "d4871946-8c3e-42f1-fd7d-cab1e0ef7e7b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total labels: 5 -> [0, 1, 2, 3, 4]\n",
            "     0     1     2     3     4\n",
            "0  864   629    25   341   509\n",
            "1  393  6278   671   380   169\n",
            "2   21   871  3329    12    21\n",
            "3  281   428    23  2572    70\n",
            "4  393   197    23    67  3124\n",
            "\n",
            "----------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------\n",
            "\n",
            "#-- Local measures --#\n",
            "True Positives(TP): {0: 864, 1: 6278, 2: 3329, 3: 2572, 4: 3124}\n",
            "False Positives(FP): {0: 1088, 1: 2125, 2: 742, 3: 800, 4: 769}\n",
            "True Negatives(TN): {0: 18235, 1: 11675, 2: 16695, 3: 17517, 4: 17118}\n",
            "False Negatives(FN): {0: 1504, 1: 1613, 2: 925, 3: 802, 4: 680}\n",
            "----------------------------\n",
            "Precision: {0: 0.4426229508196721, 1: 0.747114125907414, 2: 0.8177352001965119, 3: 0.7627520759193357, 4: 0.8024659645517596}\n",
            "Recall/Sensitivity: {0: 0.36486486486486486, 1: 0.7955899125586111, 2: 0.7825575928537847, 3: 0.7622999407231772, 4: 0.8212407991587802}\n",
            "Specificity: {0: 0.943694043368007, 1: 0.8460144927536232, 2: 0.9574468085106383, 3: 0.9563247256646831, 4: 0.9570078828199251}\n",
            "F1-Score: {0: 0.39999999999999997, 1: 0.7705904013747392, 2: 0.7997597597597598, 3: 0.7625259412985473, 4: 0.8117448356502533}\n",
            "Accuracy: {0: 0.25, 1: 0.626797124600639, 2: 0.6663330664531625, 3: 0.6161954959271682, 4: 0.6831401705663678}\n",
            "\n",
            "----------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------\n",
            "\n",
            "#-- Global measures --#\n",
            "Micro-Averages: {'Precision': 0.7453321654142271, 'Recall': 0.7453321654142271, 'Specificity': 0.9363330413535568, 'F1-score': 0.7453321654142271}\n",
            "Macro-Averages: {'Precision': 0.7145380634789386, 'Recall': 0.7053106220318437, 'Specificity': 0.9320975906233754, 'F1-Score': 0.7098943586885929}\n",
            "Correct predictions: 16167\n",
            "Total predictions: 21691\n",
            "Accuracy: 0.7453321654142271\n",
            "\n",
            "----------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------\n",
            "\n",
            "Accuracy (per class), with TNs: {0: 0.8805034346042138, 1: 0.827670462403762, 2: 0.9231478493384353, 3: 0.9261444838873265, 4: 0.9331981005947168}\n",
            "Accuracy (per class), without TNs: {0: 0.25, 1: 0.626797124600639, 2: 0.6663330664531625, 3: 0.6161954959271682, 4: 0.6831401705663678}\n",
            "Accuracy (global), with TNs: 0.8981328661656909\n",
            "Accuracy (global), without TNs: 0.7453321654142271\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfQIjY8f7rkT"
      },
      "source": [
        "**Now we need to draw the confusion matrix to show where our model is doing mistakes**\n",
        "<br>\n",
        "<br>\n",
        "***Tensorflow has its own confusion matrix function where \"labels\" is the truth data and \"predictions\" is the predicted data***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "DUneWC5k7rkT"
      },
      "outputs": [],
      "source": [
        "cm = tf.math.confusion_matrix(labels=y_test,predictions=y_predicted_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "5GbjX6za7rkU",
        "outputId": "08b882ea-c310-435e-cdc3-f94700aee0b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(69.0, 0.5, 'Truth')"
            ]
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import seaborn as sn\n",
        "plt.figure(figsize = (10,7))\n",
        "sn.heatmap(cm, annot=True, fmt='d') # here, cm is called to be visualized\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Truth')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "qHyj5hYrbND4"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ROC graph"
      ],
      "metadata": {
        "id": "l5BScGTcbYJT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Cd9dV9fcVKPr"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "ANN_Final.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}