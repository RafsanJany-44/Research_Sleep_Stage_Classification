{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SKLearn_Decision_Forest.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP0Db7IWi5yQ4lKhUL7bUf/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RafsanJany-44/Research_Sleep_Stage_Classification/blob/main/Decision_Forest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6EHYDELF1MR5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = 'https://raw.githubusercontent.com/RafsanJany-44/Thesis_Project/main/All_DATA/without_sn_and_Epoch/EEG_HMC.csv'\n",
        "dataset = pd.read_csv(data)"
      ],
      "metadata": {
        "id": "-61nFTgd179v"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "C38BCB952ZPd",
        "outputId": "74b5b6d0-4e17-41c8-edf4-65779b6b6831"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Sleep Stage  MeanP_Alpha_F4  MedianF_Alpha_F4  MeanF_Alpha_F4  \\\n",
              "0           W         0.00051           8.74146        18.48195   \n",
              "1           W         0.00040          10.24000        17.48293   \n",
              "2           W         0.00036           9.74049        17.98244   \n",
              "3           W         0.00035          10.11512        17.60780   \n",
              "4           W         0.00033           9.74049        17.60780   \n",
              "\n",
              "   Spectral Edge_Alpha_F4  PeakF_Alpha_F4  MeanP_Beta_F4  MedianF_Beta_F4  \\\n",
              "0                17.48293         8.24195        0.00071         19.73073   \n",
              "1                16.85854        10.61463        0.00051         17.23317   \n",
              "2                17.48293         8.74146        0.00047         17.60780   \n",
              "3                17.10829         9.61561        0.00047         17.35805   \n",
              "4                17.23317         8.11707        0.00043         17.23317   \n",
              "\n",
              "   MeanF_Beta_F4  Spectral Edge_Beta_F4  ...  MeanP_Delta_O2  \\\n",
              "0       29.84585               33.84195  ...         0.00724   \n",
              "1       26.34927               29.34634  ...         0.00723   \n",
              "2       25.47512               28.22244  ...         0.00230   \n",
              "3       26.47415               28.72195  ...         0.00091   \n",
              "4       25.84976               28.09756  ...         0.00175   \n",
              "\n",
              "   MedianF_Delta_O2  MeanF_Delta_O2  Spectral Edge_Delta_O2  PeakF_Delta_O2  \\\n",
              "0           0.74927         3.87122                 1.99805         0.87415   \n",
              "1           0.49951         3.74634                 1.24878         0.49951   \n",
              "2           0.62439         5.24488                 2.12293         0.62439   \n",
              "3           0.87415         6.61854                 3.12195         0.62439   \n",
              "4           0.49951         5.74439                 2.24780         0.49951   \n",
              "\n",
              "   MeanP_Gamma_O2  MedianF_Gamma_O2  MeanF_Gamma_O2  Spectral Edge_Gamma_O2  \\\n",
              "0        0.000210          35.21561        42.20878                49.95122   \n",
              "1        0.000095          34.34146        43.33268                49.95122   \n",
              "2        0.000074          34.59122        45.95512                49.95122   \n",
              "3        0.000082          32.46829        43.95707                49.95122   \n",
              "4        0.000077          33.59220        44.83122                49.95122   \n",
              "\n",
              "   PeakF_Gamma_O2  \n",
              "0        49.95122  \n",
              "1        49.95122  \n",
              "2        49.95122  \n",
              "3        49.95122  \n",
              "4        49.95122  \n",
              "\n",
              "[5 rows x 76 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f0563884-098a-4387-92b5-c4403ccf0c6e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sleep Stage</th>\n",
              "      <th>MeanP_Alpha_F4</th>\n",
              "      <th>MedianF_Alpha_F4</th>\n",
              "      <th>MeanF_Alpha_F4</th>\n",
              "      <th>Spectral Edge_Alpha_F4</th>\n",
              "      <th>PeakF_Alpha_F4</th>\n",
              "      <th>MeanP_Beta_F4</th>\n",
              "      <th>MedianF_Beta_F4</th>\n",
              "      <th>MeanF_Beta_F4</th>\n",
              "      <th>Spectral Edge_Beta_F4</th>\n",
              "      <th>...</th>\n",
              "      <th>MeanP_Delta_O2</th>\n",
              "      <th>MedianF_Delta_O2</th>\n",
              "      <th>MeanF_Delta_O2</th>\n",
              "      <th>Spectral Edge_Delta_O2</th>\n",
              "      <th>PeakF_Delta_O2</th>\n",
              "      <th>MeanP_Gamma_O2</th>\n",
              "      <th>MedianF_Gamma_O2</th>\n",
              "      <th>MeanF_Gamma_O2</th>\n",
              "      <th>Spectral Edge_Gamma_O2</th>\n",
              "      <th>PeakF_Gamma_O2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>W</td>\n",
              "      <td>0.00051</td>\n",
              "      <td>8.74146</td>\n",
              "      <td>18.48195</td>\n",
              "      <td>17.48293</td>\n",
              "      <td>8.24195</td>\n",
              "      <td>0.00071</td>\n",
              "      <td>19.73073</td>\n",
              "      <td>29.84585</td>\n",
              "      <td>33.84195</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00724</td>\n",
              "      <td>0.74927</td>\n",
              "      <td>3.87122</td>\n",
              "      <td>1.99805</td>\n",
              "      <td>0.87415</td>\n",
              "      <td>0.000210</td>\n",
              "      <td>35.21561</td>\n",
              "      <td>42.20878</td>\n",
              "      <td>49.95122</td>\n",
              "      <td>49.95122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>W</td>\n",
              "      <td>0.00040</td>\n",
              "      <td>10.24000</td>\n",
              "      <td>17.48293</td>\n",
              "      <td>16.85854</td>\n",
              "      <td>10.61463</td>\n",
              "      <td>0.00051</td>\n",
              "      <td>17.23317</td>\n",
              "      <td>26.34927</td>\n",
              "      <td>29.34634</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00723</td>\n",
              "      <td>0.49951</td>\n",
              "      <td>3.74634</td>\n",
              "      <td>1.24878</td>\n",
              "      <td>0.49951</td>\n",
              "      <td>0.000095</td>\n",
              "      <td>34.34146</td>\n",
              "      <td>43.33268</td>\n",
              "      <td>49.95122</td>\n",
              "      <td>49.95122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>W</td>\n",
              "      <td>0.00036</td>\n",
              "      <td>9.74049</td>\n",
              "      <td>17.98244</td>\n",
              "      <td>17.48293</td>\n",
              "      <td>8.74146</td>\n",
              "      <td>0.00047</td>\n",
              "      <td>17.60780</td>\n",
              "      <td>25.47512</td>\n",
              "      <td>28.22244</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00230</td>\n",
              "      <td>0.62439</td>\n",
              "      <td>5.24488</td>\n",
              "      <td>2.12293</td>\n",
              "      <td>0.62439</td>\n",
              "      <td>0.000074</td>\n",
              "      <td>34.59122</td>\n",
              "      <td>45.95512</td>\n",
              "      <td>49.95122</td>\n",
              "      <td>49.95122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>W</td>\n",
              "      <td>0.00035</td>\n",
              "      <td>10.11512</td>\n",
              "      <td>17.60780</td>\n",
              "      <td>17.10829</td>\n",
              "      <td>9.61561</td>\n",
              "      <td>0.00047</td>\n",
              "      <td>17.35805</td>\n",
              "      <td>26.47415</td>\n",
              "      <td>28.72195</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00091</td>\n",
              "      <td>0.87415</td>\n",
              "      <td>6.61854</td>\n",
              "      <td>3.12195</td>\n",
              "      <td>0.62439</td>\n",
              "      <td>0.000082</td>\n",
              "      <td>32.46829</td>\n",
              "      <td>43.95707</td>\n",
              "      <td>49.95122</td>\n",
              "      <td>49.95122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>W</td>\n",
              "      <td>0.00033</td>\n",
              "      <td>9.74049</td>\n",
              "      <td>17.60780</td>\n",
              "      <td>17.23317</td>\n",
              "      <td>8.11707</td>\n",
              "      <td>0.00043</td>\n",
              "      <td>17.23317</td>\n",
              "      <td>25.84976</td>\n",
              "      <td>28.09756</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00175</td>\n",
              "      <td>0.49951</td>\n",
              "      <td>5.74439</td>\n",
              "      <td>2.24780</td>\n",
              "      <td>0.49951</td>\n",
              "      <td>0.000077</td>\n",
              "      <td>33.59220</td>\n",
              "      <td>44.83122</td>\n",
              "      <td>49.95122</td>\n",
              "      <td>49.95122</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 76 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f0563884-098a-4387-92b5-c4403ccf0c6e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f0563884-098a-4387-92b5-c4403ccf0c6e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f0563884-098a-4387-92b5-c4403ccf0c6e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = dataset.iloc[:, 1:].values\n",
        "y = dataset.iloc[:, 0].values"
      ],
      "metadata": {
        "id": "96jlJrST2Z1X"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 0)"
      ],
      "metadata": {
        "id": "xuVvsVaV2eV6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmkDTJlj2gWF",
        "outputId": "d08b5958-4c87-4fbc-89b0-29446d818adc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((72662, 75), (35789, 75))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4apEC_LhCe3m"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train =sc.fit_transform(X_train)\n",
        "\n",
        "X_test =sc.fit_transform(X_test)"
      ],
      "metadata": {
        "id": "aYQobtGs2iMk"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "N=200\n",
        "k_range = range (1,N+1)\n",
        "scores={}\n",
        "scores_list = []\n",
        "for k in k_range:\n",
        "  classifier = RandomForestClassifier(n_estimators=k, random_state=1)\n",
        "  classifier.fit(X_train, y_train)\n",
        "  y_pred=classifier.predict(X_test)\n",
        "  scores[k] = accuracy_score(y_test,y_pred)\n",
        "  scores_list.append(accuracy_score(y_test,y_pred))\n",
        "  print(str(k)+\"/\"+str(N)+\" round completed......................... Accurecy: \"+str(accuracy_score(y_test,y_pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "m5Q17eNfChy_",
        "outputId": "a6c680af-f5bc-4410-f2ad-19fadddcfc2f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/50 round completed......................... Accurecy: 0.7656821928525525\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-373669c517d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mk_range\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m   \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    465\u001b[0m                     \u001b[0mn_samples_bootstrap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_samples_bootstrap\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m                 )\n\u001b[0;32m--> 467\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m             )\n\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1047\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"balanced\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    940\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m             \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m         )\n\u001b[1;32m    944\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    418\u001b[0m             )\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "#plot the relationship between K and the testing accuracy\n",
        "plt.figure(figsize = (25,10))\n",
        "plt.plot(k_range,scores_list)\n",
        "plt.xlabel('Value of n_estimators')\n",
        "plt.ylabel ('Testing Accuracy')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 644
        },
        "id": "7cF1NqKoCwKa",
        "outputId": "c18d6ab0-0da1-4852-b842-046131328a45"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Testing Accuracy')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1800x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The best n_estimators:\")\n",
        "best=list(scores.keys())[scores_list.index(max(scores_list))]\n",
        "print(best)"
      ],
      "metadata": {
        "id": "WoxmrlTtC4fq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "classifier = RandomForestClassifier(n_estimators=best, random_state=0)\n",
        "classifier.fit(X_train, y_train)\n",
        "y_pred=classifier.predict(X_test)"
      ],
      "metadata": {
        "id": "9NvepL2Z2ipd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test,y_pred))\n",
        "print(\"Accurecy: \",accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "f4NzJ4z12lI3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test, y_pred)\n",
        "import seaborn as sn\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize = (15,10))\n",
        "sn.heatmap(cm, annot=True, fmt='d') # here, cm is called to be visualized\n",
        "plt.xlabel('Predicted',fontsize=14.0, fontweight='bold')\n",
        "plt.ylabel('Truth',fontsize=12.0, fontweight='bold')"
      ],
      "metadata": {
        "id": "MVXk7tlTtd30"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def confusion_details(y_test,y_pred):\n",
        "    labels = list(set(y_test))\n",
        "    labels.sort()\n",
        "\n",
        "    print(\"Total labels: %s -> %s\" % (len(labels), labels))\n",
        "\n",
        "    df = pd.DataFrame(\n",
        "        data=confusion_matrix(y_test, y_pred, labels=labels),\n",
        "        columns=labels,\n",
        "        index=labels\n",
        "    )\n",
        "\n",
        "    print(df)\n",
        "\n",
        "    print()\n",
        "    print(\"----------------------------------------------------------------------------------------\")\n",
        "    print(\"----------------------------------------------------------------------------------------\")\n",
        "    print()\n",
        "    #\n",
        "    # Local (metrics per class)\n",
        "    #\n",
        "    tps = {}\n",
        "    fps = {}\n",
        "    fns = {}\n",
        "    tns = {}\n",
        "\n",
        "    precision_local = {}\n",
        "    recall_local = {}\n",
        "    f1_local = {}\n",
        "    accuracy_local = {}\n",
        "    specificity_local={}\n",
        "\n",
        "    for label in labels:\n",
        "        tps[label] = df.loc[label, label]\n",
        "        fps[label] = df[label].sum() - tps[label]\n",
        "        fns[label] = df.loc[label].sum() - tps[label]\n",
        "        tns[label]=len(y_test) - (tps[label] + fps[label] + fns[label])\n",
        "        \n",
        "        tp, fp, fn, tn = tps[label], fps[label], fns[label], tns[label]\n",
        "        \n",
        "        precision_local[label] = tp / (tp + fp) if (tp + fp) > 0. else 0.\n",
        "        specificity_local[label] = tn / (tn + fp) if (tn + fp) > 0. else 0.\n",
        "        recall_local[label] = tp / (tp + fn) if (tp + fp) > 0. else 0.\n",
        "        p, r = precision_local[label], recall_local[label]\n",
        "        \n",
        "        f1_local[label] = 2. * p * r / (p + r) if (p + r) > 0. else 0.\n",
        "        accuracy_local[label] = tp / (tp + fp + fn) if (tp + fp + fn) > 0. else 0.\n",
        "\n",
        "\n",
        "\n",
        "    print(\"#-- Local measures --#\")\n",
        "    print(\"True Positives(TP):\", tps)\n",
        "    print(\"False Positives(FP):\", fps)\n",
        "    print(\"True Negatives(TN):\", tns)\n",
        "    print(\"False Negatives(FN):\", fns)\n",
        "    print(\"----------------------------\")\n",
        "\n",
        "    print(\"Precision:\", precision_local)\n",
        "    print(\"Recall/Sensitivity:\", recall_local)\n",
        "    print(\"Specificity:\",specificity_local)\n",
        "    print(\"F1-Score:\", f1_local)\n",
        "    print(\"Accuracy:\", accuracy_local)\n",
        "\n",
        "\n",
        "    print()\n",
        "    print(\"----------------------------------------------------------------------------------------\")\n",
        "    print(\"----------------------------------------------------------------------------------------\")\n",
        "    print()\n",
        "    #\n",
        "    # Global\n",
        "    #\n",
        "    micro_averages = {}\n",
        "    macro_averages = {}\n",
        "\n",
        "    correct_predictions = sum(tps.values())\n",
        "    true_negative=sum(tns.values())\n",
        "\n",
        "    den = sum(list(tps.values()) + list(fps.values()))\n",
        "    micro_averages[\"Precision\"] = 1. * correct_predictions / den if den > 0. else 0.\n",
        "\n",
        "    den = sum(list(tps.values()) + list(fns.values()))\n",
        "    micro_averages[\"Recall\"] = 1. * correct_predictions / den if den > 0. else 0.\n",
        "\n",
        "    den = sum(list(tns.values()) + list(fps.values()))\n",
        "    micro_averages[\"Specificity\"] = 1. * true_negative / den if den > 0. else 0.\n",
        "\n",
        "\n",
        "    micro_avg_p, micro_avg_r = micro_averages[\"Precision\"], micro_averages[\"Recall\"]\n",
        "    micro_averages[\"F1-score\"] = 2. * micro_avg_p * micro_avg_r / (micro_avg_p + micro_avg_r) if (micro_avg_p + micro_avg_r) > 0. else 0.\n",
        "\n",
        "    macro_averages[\"Precision\"] = np.mean(list(precision_local.values()))\n",
        "    macro_averages[\"Recall\"] = np.mean(list(recall_local.values()))\n",
        "    macro_averages[\"Specificity\"]=np.mean(list(specificity_local.values()))\n",
        "\n",
        "\n",
        "    macro_avg_p, macro_avg_r = macro_averages[\"Precision\"], macro_averages[\"Recall\"]\n",
        "    macro_averages[\"F1-Score\"] = 2. * macro_avg_p * macro_avg_r / (macro_avg_p + macro_avg_r) if (macro_avg_p + macro_avg_r) > 0. else 0.\n",
        "\n",
        "    total_predictions = df.values.sum()\n",
        "    accuracy_global = correct_predictions / total_predictions if total_predictions > 0. else 0.\n",
        "\n",
        "    print(\"#-- Global measures --#\")\n",
        "    print(\"Micro-Averages:\", micro_averages)\n",
        "    print(\"Macro-Averages:\", macro_averages)\n",
        "    print(\"Correct predictions:\", correct_predictions)\n",
        "    print(\"Total predictions:\", total_predictions)\n",
        "    print(\"Accuracy:\", accuracy_global)\n",
        "\n",
        "\n",
        "    print()\n",
        "    print(\"----------------------------------------------------------------------------------------\")\n",
        "    print(\"----------------------------------------------------------------------------------------\")\n",
        "    print()\n",
        "\n",
        "\n",
        "\n",
        "    accuracy_local_new = {}\n",
        "    for label in labels:\n",
        "        tp, fp, fn, tn = tps[label], fps[label], fns[label], tns[label]\n",
        "        accuracy_local_new[label] = (tp + tn) / (tp + fp + fn + tn) if (tp + fp + fn + tn) > 0. else 0.\n",
        "\n",
        "    total_true = sum(list(tps.values()) + list(tns.values()))\n",
        "    total_predictions = sum(list(tps.values()) + list(tns.values()) + list(fps.values()) + list(fns.values()))\n",
        "    accuracy_global_new = 1. * total_true / total_predictions if total_predictions > 0. else 0.\n",
        "\n",
        "    print(\"Accuracy (per class), with TNs:\", accuracy_local_new)\n",
        "    print(\"Accuracy (per class), without TNs:\", accuracy_local)\n",
        "    print(\"Accuracy (global), with TNs:\", accuracy_global_new)\n",
        "    print(\"Accuracy (global), without TNs:\", accuracy_global)"
      ],
      "metadata": {
        "id": "QHeH4r1lSYTm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_details(y_test,y_pred)"
      ],
      "metadata": {
        "id": "H2p1lfXXSfBR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}